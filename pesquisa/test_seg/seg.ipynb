{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurando o DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 773.52 MiB (download: 773.52 MiB, generated: 774.69 MiB, total: 1.51 GiB) to /home/lorran/tensorflow_datasets/oxford_iiit_pet/3.2.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 63.81 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 46.03 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 36.16 url/s]\n",
      "Dl Completed...:  50%|█████     | 1/2 [00:00<00:00, 22.99 url/s]\n",
      "Dl Completed...: 100%|██████████| 2/2 [00:00<00:00, 37.19 url/s]\n",
      "Dl Completed...: 100%|██████████| 2/2 [00:00<00:00, 31.69 url/s]\n",
      "Dl Completed...: 100%|██████████| 2/2 [00:00<00:00, 27.60 url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 100%|██████████| 811092049/811092049 [00:00<00:00, 9950791436.41 MiB/s] \n",
      "Dl Completed...: 100%|██████████| 2/2 [00:00<00:00, 23.63 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset oxford_iiit_pet downloaded and prepared to /home/lorran/tensorflow_datasets/oxford_iiit_pet/3.2.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Carrega o Oxford-IIIT Pet Dataset com informações de segmentação\n",
    "dataset, info = tfds.load(\"oxford_iiit_pet:3.*.*\", with_info=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128  # Tamanho das imagens de entrada\n",
    "\n",
    "def preprocess_data(data):\n",
    "    image = tf.image.resize(data['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    mask = tf.image.resize(data['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normaliza a imagem\n",
    "    mask = tf.cast(mask, tf.int32) - 1  # Ajusta as classes da máscara\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Input\n",
    "\n",
    "def unet_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder (Downsampling)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    # Decoder (Upsampling)\n",
    "    u1 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u1 = concatenate([u1, c3])  # c3 deve ser ajustado para ter a mesma dimensão que u1\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u2 = concatenate([u2, c2])  # c2 deve ser ajustado para ter a mesma dimensão que u2\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u3 = concatenate([u3, c1])  # c1 deve ser ajustado para ter a mesma dimensão que u3\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u3)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    # Camada final de saída\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "#Instanciando o modelo\n",
    "input_shape = (128, 128, 3)  # Pode ser alterado conforme a resolução da base de dados\n",
    "model = unet_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 11:16:58.144369: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388608 bytes after encountering the first element of size 8388608 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Preparando os dados\n",
    "train_data = dataset['train'].map(preprocess_data).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = dataset['test'].map(preprocess_data).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Treinando a U-Net\n",
    "model.fit(train_data, epochs=10, validation_data=test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação e Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_sample(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    titles = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(titles[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Pegando uma amostra para testar\n",
    "for image, mask in test_data.take(1):\n",
    "    pred_mask = model.predict(image)\n",
    "    display_sample([image[0], mask[0], tf.argmax(pred_mask[0], axis=-1)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
