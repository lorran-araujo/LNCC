"Authors","Author full names","Author(s) ID","Title","Year","DOI","Link","Abstract","Author Keywords","Publication Stage"
"Chu J.; Xiao X.; Meng G.; Wang L.; Pan C.","Chu, Jun (38561235500); Xiao, Xu (57201587542); Meng, Gaofeng (16317032400); Wang, Lingfeng (55721448100); Pan, Chunhong (8558023500)","38561235500; 57201587542; 16317032400; 55721448100; 8558023500","Learnable contextual regularization for semantic segmentation of indoor scene images","2017","10.1109/ICIP.2017.8296485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045299439&doi=10.1109%2fICIP.2017.8296485&partnerID=40&md5=529d8fc09cc37f2b4f6a155fae92a625","Semantic segmentation of indoor scene images has a wide range of applications. However, due to a large number of classes and uneven distribution in indoor scenes, mislabels are often made when facing small objects or boundary regions. Technically, contextual information may benefit for segmentation results, but has not yet been exploited sufficiently. In this paper, we propose a learnable contextual regularization model for enhancing the semantic segmentation results of color indoor scene images. This regularization model is combined with a deep convolutional segmentation network without significantly increasing the number of additional parameters. Our model, derived from the inherent contextual regularization on the indoor scene objects, benefits much from the learnable constraint layers bridging the lower layers and the higher layers in the deep convolutional network. The constraint layers are further integrated with a weighted L1-norm based contextual regularization between the neighboring pixels of RGB values to improve the segmentation results. Experimental results on NYUDv2 indoor scene dataset demonstrate the effectiveness and efficiency of the proposed method. © 2017 IEEE.","Contextual constraints; Deep convolutional neural networks; End-to-end training; Semantic segmentation","Final"
"Mai H.; Sun R.; Zhang T.; Wu F.","Mai, Huayu (58568844400); Sun, Rui (57217479666); Zhang, Tianzhu (55729040600); Wu, Feng (57211743319)","58568844400; 57217479666; 55729040600; 57211743319","RankMatch: Exploring the Better Consistency Regularization for Semi-Supervised Semantic Segmentation","2024","10.1109/CVPR52733.2024.00326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206815270&doi=10.1109%2fCVPR52733.2024.00326&partnerID=40&md5=e0cc372c91df8c5e058474a86f77803c","The key lie in semi-supervised semantic segmentation is how to fully exploit substantial unlabeled data to im-prove the model's generalization performance by resorting to constructing effective supervision signals. Most methods tend to directly apply contrastive learning to seek additional supervision to complement independent regular pixel-wise consistency regularization. However, these methods tend not to be preferred ascribed to their complicated designs, heavy memory footprints and susceptibility to confirmation bias. In this paper, we analyze the bottlenecks exist in con-trastive learning-based methods and offer a fresh perspective on inter-pixel correlations to construct more safe and effective supervision signals, which is in line with the nature of semantic segmentation. To this end, we develop a coherent RankMatch network, including the construction of representative agents to model inter-pixel correlation beyond regular individual pixel-wise consistency, and fur-ther unlock the potential of agents by modeling inter-agent relationships in pursuit of rank-aware correlation consis-tency. Extensive experimental results on multiple bench-marks, including mitochondria segmentation, demonstrate that RankMatch performs favorably against state-of-the-art methods. Particularly in the low-data regimes, RankMatch achieves significant improvements. © 2024 IEEE.","","Final"
"Iqbal J.; Rawal H.; Hafiz R.; Chi Y.-T.; Ali M.","Iqbal, Javed (57220635316); Rawal, Hamza (57325560200); Hafiz, Rehan (15765093200); Chi, Yu-Tseh (57776567000); Ali, Mohsen (57054179100)","57220635316; 57325560200; 15765093200; 57776567000; 57054179100","Distribution regularized self-supervised learning for domain adaptation of semantic segmentation","2022","10.1016/j.imavis.2022.104504","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134337267&doi=10.1016%2fj.imavis.2022.104504&partnerID=40&md5=6df145afc814f851665b44ef564b5e0e","This paper proposes a novel pixel-level distribution regularization scheme (DRSL) for self-supervised domain adaptation of semantic segmentation. In a typical setting, the classification loss forces the semantic segmentation model to greedily learn the representations that capture inter-class variations in order to determine the decision (class) boundary. Due to the domain-shift, this decision boundary is unaligned in the target domain, resulting in noisy pseudo labels adversely affecting self-supervised domain adaptation. To overcome this limitation, along with capturing inter-class variation, we capture pixel-level intra-class variations through class-aware multi-modal distribution learning (MMDL). Thus, the information necessary for capturing the intra-class variations is explicitly disentangled from the information necessary for inter-class discrimination. Features captured thus are much more informative, resulting in pseudo-labels with low noise. This disentanglement allows us to perform separate alignments in discriminative space and multi-modal distribution space, using cross-entropy based self-learning for former. For later, we propose novel stochastic mode alignment method, by explicitly decreasing the distance between the target and source pixels that map to the same mode. The distance metric learning loss, computed over pseudo-labels and backpropagated from multi-modal modeling head, acts as the regularizer over the base network shared with the segmentation head. The results from comprehensive experiments on synthetic to real domain adaptation setups, i.e., GTA-V/SYNTHIA to Cityscapes, show that DRSL outperforms many existing approaches (a minimum margin of 2.3% and 2.5% in mIoU for SYNTHIA to Cityscapes). © 2022 Elsevier B.V.","Domain adaptation; Multi-modal distribution learning; Self-supervised learning; Semantic segmentation","Final"
"Zhang B.; Zhang Y.; Li Y.; Wan Y.; Guo H.; Zheng Z.; Yang K.","Zhang, Bin (57218111145); Zhang, Yongjun (55577971100); Li, Yansheng (55969097400); Wan, Yi (57213301632); Guo, Haoyu (57236569000); Zheng, Zhi (57213530274); Yang, Kun (57736232700)","57218111145; 55577971100; 55969097400; 57213301632; 57236569000; 57213530274; 57736232700","Semi-supervised Deep Learning via Transformation Consistency Regularization for Remote Sensing Image Semantic Segmentation","2023","10.1109/JSTARS.2022.3203750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137916566&doi=10.1109%2fJSTARS.2022.3203750&partnerID=40&md5=33d58d0ce24a6cdae34ecba353707a0d","Deep convolutional neural networks have gotten a lot of press in the last several years, especially in domains like computer vision and remote sensing (RS). However, achieving superior performance with deep networks highly depends on a massive number of accurately labeled training samples. In real-world applications, gathering a large number of labeled samples is time consuming and labor intensive, especially for pixel-level data annotation. This dearth of labels in land-cover classification is especially pressing in the RS domain because high-precision high-quality labeled samples are extremely difficult to acquire, but unlabeled data are readily available. In this study, we offer a new semisupervised deep semantic labeling framework for the semantic segmentation of high-resolution RS images to take advantage of the limited amount of labeled examples and numerous unlabeled samples. Our model uses transformation consistency regularization to encourage consistent network predictions under different random transformations or perturbations. We try three different transforms to compute the consistency loss and analyze their performance. Then, we present a deep semisupervised semantic labeling technique by using a hybrid transformation consistency regularization. A weighted sum of losses, which contains a supervised term computed on labeled samples and an unsupervised regularization term computed on unlabeled data, may be used to update the network parameters in our technique. Our comprehensive experiments on two RS datasets confirmed that the suggested approach utilized latent information from unlabeled samples to obtain more precise predictions and outperformed existing semisupervised algorithms in terms of performance. Our experiments further demonstrated that our semisupervised semantic labeling strategy has the potential to partially tackle the problem of limited labeled samples for high-resolution RS image land-cover segmentation.  © 2008-2012 IEEE.","Consistency regularization; convolutional neural network (CNN); remote sensing (RS) imagery; semantic segmentation; semisupervised learning (SSL); unlabeled data","Final"
"Bashir R.M.S.; Qaiser T.; Raza S.E.A.; Rajpoot N.M.","Bashir, Raja Muhammad Saad (57204786948); Qaiser, Talha (57190982929); Raza, Shan E Ahmed (54960699400); Rajpoot, Nasir M. (8042017200)","57204786948; 57190982929; 54960699400; 8042017200","Consistency regularisation in varying contexts and feature perturbations for semi-supervised semantic segmentation of histology images","2024","10.1016/j.media.2023.102997","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174701285&doi=10.1016%2fj.media.2023.102997&partnerID=40&md5=455869bc80730ecd05456c1056af4d7b","Semantic segmentation of various tissue and nuclei types in histology images is fundamental to many downstream tasks in the area of computational pathology (CPath). In recent years, Deep Learning (DL) methods have been shown to perform well on segmentation tasks but DL methods generally require a large amount of pixel-wise annotated data. Pixel-wise annotation sometimes requires expert's knowledge and time which is laborious and costly to obtain. In this paper, we present a consistency based semi-supervised learning (SSL) approach that can help mitigate this challenge by exploiting a large amount of unlabelled data for model training thus alleviating the need for a large annotated dataset. However, SSL models might also be susceptible to changing context and features perturbations exhibiting poor generalisation due to the limited training data. We propose an SSL method that learns robust features from both labelled and unlabelled images by enforcing consistency against varying contexts and feature perturbations. The proposed method incorporates context-aware consistency by contrasting pairs of overlapping images in a pixel-wise manner from changing contexts resulting in robust and context invariant features. We show that cross-consistency training makes the encoder features invariant to different perturbations and improves the prediction confidence. Finally, entropy minimisation is employed to further boost the confidence of the final prediction maps from unlabelled data. We conduct an extensive set of experiments on two publicly available large datasets (BCSS and MoNuSeg) and show superior performance compared to the state-of-the-art methods. © 2023 The Author(s)","Computational pathology; Contrastive learning; Deep learning; Semi-supervised learning; Whole slide images","Final"
"Zhou Q.; Zhuang C.; Yi R.; Lu X.; Ma L.","Zhou, Qianyu (57219734464); Zhuang, Chuyun (57313923800); Yi, Ran (35306170600); Lu, Xuequan (55794820600); Ma, Lizhuang (8930473900)","57219734464; 57313923800; 35306170600; 55794820600; 8930473900","Domain Adaptive Semantic Segmentation via Regional Contrastive Consistency Regularization","2022","10.1109/ICME52920.2022.9859793","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137676788&doi=10.1109%2fICME52920.2022.9859793&partnerID=40&md5=daad03b3642408d898ddb132df6aaa03","Unsupervised domain adaptation (UDA) for semantic seg-mentation has been well-studied in recent years. However, most existing works largely neglect the local regional consis-tency across different domains, and are less robust to changes in outdoor environments. In this paper, we propose a novel and fully end-to-end trainable approach, called regional contrastive consistency regularization (RCCR) for domain adaptive semantic segmentation. Our core idea is to pull the sim-ilar regional features extracted from the same location of dif-ferent images, i.e., the original image and augmented image, to be closer, and meanwhile push the features from the dif-ferent locations of the two images to be separated. We pro-pose a region-wise contrastive loss with two sampling strate-gies to realize effective regional consistency. Besides, we present momentum projection heads, where the teacher pro-jection head is the exponential moving average of the student. Finally, a memory bank mechanism is designed to learn more robust and stable region-wise features under varying environ-ments. Extensive experiments demonstrate that our approach outperforms the state-of-the-art methods.  © 2022 IEEE.","Contrastive Learning; Domain Adaptation; Semantic Segmen-tation","Final"
"Volpi M.; Tuia D.","Volpi, Michele (35796556100); Tuia, Devis (15766793800)","35796556100; 15766793800","Deep multi-task learning for a geographically-regularized semantic segmentation of aerial images","2018","10.1016/j.isprsjprs.2018.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049446921&doi=10.1016%2fj.isprsjprs.2018.06.007&partnerID=40&md5=3847a486732b09a64005c2bc4aa83ee2","When approaching the semantic segmentation of overhead imagery in the decimeter spatial resolution range, successful strategies usually combine powerful methods to learn the visual appearance of the semantic classes (e.g. convolutional neural networks) with strategies for spatial regularization (e.g. graphical models such as conditional random fields). In this paper, we propose a method to learn evidence in the form of semantic class likelihoods, semantic boundaries across classes and shallow-to-deep visual features, each one modeled by a multi-task convolutional neural network architecture. We combine this bottom-up information with top-down spatial regularization encoded by a conditional random field model optimizing the label space across a hierarchy of segments with constraints related to structural, spatial and data-dependent pairwise relationships between regions. Our results show that such strategy provide better regularization than a series of strong baselines reflecting state-of-the-art technologies. The proposed strategy offers a flexible and principled framework to include several sources of visual and structural information, while allowing for different degrees of spatial regularization accounting for priors about the expected output structures. © 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Aerial imagery; Conditional random fields; Convolutional neural networks; Decimeter resolution; Multi-task learning; Semantic boundary detection; Semantic segmentation","Final"
"Zhang H.; Li H.; Zhang X.; Yang G.; Li A.; Du W.; Xue S.; Liu C.","Zhang, HaiKuan (58222274100); Li, Haitao (36340209300); Zhang, Xiufeng (58964323300); Yang, Guanyu (57194783935); Li, Atao (58964411100); Du, Weisheng (59489177800); Xue, Shanshan (58800039700); Liu, Chi (57209296704)","58222274100; 36340209300; 58964323300; 57194783935; 58964411100; 59489177800; 58800039700; 57209296704","Noise-robust consistency regularization for semi-supervised semantic segmentation","2025","10.1016/j.neunet.2024.107041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213258045&doi=10.1016%2fj.neunet.2024.107041&partnerID=40&md5=387b4fb3bfd12ef5fe5f8060d8731c2f","The essential of semi-supervised semantic segmentation (SSSS) is to learn more helpful information from unlabeled data, which can be achieved by assigning adequate quality pseudo-labels or managing noisy pseudo-labels during training. However, most relevant state-of-the-art (SOTA) methods are mainly devoted to improving one aspect. By revisiting the representative SSSS methods from a robust learning view, this paper discovers that the appropriate combination of multiple noise-robust methods contributes both to assigning sufficient quality pseudo labels and managing noisy labels. Therefore, from five different noise management perspectives, we summarize the reasons why noise-robust techniques can successfully harvest performance gains in SSSS. Subsequently, we present a novel feature perturbation method, multi-view learning strategy, and robust loss function to exploit the advantages of different noise-robust techniques. The outcome of this paper is a new SSSS approach with noise-robust consistency regularization called NRCR that can simultaneously produce adequate quality pseudo-labels and manage noisy pseudo-labels. Abundant experiments on public benchmarks demonstrate the performance superiority of our approach compared with previous SOTA methods and the correctness of our analytical viewpoints. Code is available at https://github.com/zhanghk1996/NRCR. © 2024","Consistency regularization; Feature perturbation; Multi-view learning; Robust learning; Semi-supervised semantic segmentation","Final"
"Cai M.; Chen H.; Zhang T.; Zhuang Y.; Chen L.","Cai, Miaoxin (58864958000); Chen, He (58567724000); Zhang, Tong (59078580100); Zhuang, Yin (57189629709); Chen, Liang (57037284200)","58864958000; 58567724000; 59078580100; 57189629709; 57037284200","Consistency Regularization Based on Masked Image Modeling for Semisupervised Remote Sensing Semantic Segmentation","2024","10.1109/JSTARS.2024.3435509","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200803682&doi=10.1109%2fJSTARS.2024.3435509&partnerID=40&md5=430a4fddb13ccf663d99bfc102df197e","Semisupervised semantic segmentation aims to effectively leverage both unlabeled and scare labeled images, reducing the reliance on labor-intensive pixel-level labeling for extensive training processes. The leading semisupervised learning method, consistency regularization, employs weak and strong data augmentations to diversify input representations. Ultimately the model is compelled to maintain consistent predictions across different input views, thus boosting the model's generalization. However, previous methods suffered from limited input representation space introduced by linear transformations such as cutmix. To address such issue, a consistency regularization based on masked image modeling (MIM) called MIMSeg is proposed to achieve accurate segmentation with limited labeled images. First, MIM pixel-wise perception with ViT encoder-decoder lays the foundation for expanding the data representation space. Second, collaborating with weak data augmentations, two MIM-related strong data augmentations are developed to generate more challenging input views for consistent predictions. Precisely, weak data augmentations are employed to replicate input views from various perspectives while a controllable generative strong data augmentation called masked image reconstruction (MIR) is crafted to simulate multiple imaging diversity while preserving the original semantic information intact. In addition, a more severe strong data augmentation masked context perturbation (MCP) is designed to further generate more challenging input views and alleviate semantic deficiency via masked category prediction. Leveraging the MIM perception and two MIM-related strong data augmentations, the model is compelled to achieve consistency predictions across diverse input views from weak data augmentations, MIR and MCP. These components result in the generation of more stable pixel-level pseudo-labels and facilitate collaborative training between unlabeled and labeled images. Extensive experiments have shown that MIMSeg can achieve state-of-the-art performance in pixel-level prediction with very limited sample annotations.  © 2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.","Consistency regularization; masked image modeling (MIM); semisupervised semantic segmentation","Final"
"Zhou Q.; Feng Z.; Gu Q.; Cheng G.; Lu X.; Shi J.; Ma L.","Zhou, Qianyu (57219734464); Feng, Zhengyang (57219739023); Gu, Qiqi (57222708139); Cheng, Guangliang (56683735000); Lu, Xuequan (55794820600); Shi, Jianping (55923803000); Ma, Lizhuang (8930473900)","57219734464; 57219739023; 57222708139; 56683735000; 55794820600; 55923803000; 8930473900","Uncertainty-aware consistency regularization for cross-domain semantic segmentation","2022","10.1016/j.cviu.2022.103448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131041701&doi=10.1016%2fj.cviu.2022.103448&partnerID=40&md5=61c48ee3c90afdaa0a6641c6a5076203","Unsupervised domain adaptation (UDA) aims to adapt existing models of the source domain to a new target domain with only unlabeled data. Most existing methods suffer from noticeable negative transfer resulting from either the error-prone discriminator network or the unreasonable teacher model. Besides, the local regional consistency in UDA has been largely neglected, and only extracting the global-level pattern information is not powerful enough for feature alignment due to the abuse use of contexts. To this end, we propose an uncertainty-aware consistency regularization method for cross-domain semantic segmentation. Firstly, we introduce an uncertainty-guided consistency loss with a dynamic weighting scheme by exploiting the latent uncertainty information of the target samples. As such, more meaningful and reliable knowledge from the teacher model can be transferred to the student model. We further reveal the reason why the current consistency regularization is often unstable in minimizing the domain discrepancy. Besides, we design a ClassDrop mask generation algorithm to produce strong class-wise perturbations. Guided by this mask, we propose a ClassOut strategy to realize effective regional consistency in a fine-grained manner. Experiments demonstrate that our method outperforms the state-of-the-art methods on four domain adaptation benchmarks, i.e., GTAV → Cityscapes, SYNTHIA → Cityscapes, Virtual KITTI ⟶ KITTI and Cityscapes ⟶ KITTI. © 2022 Elsevier Inc.","Consistency regularization; Domain adaptation; Semantic segmentation; Transfer learning","Final"
"Yang Z.; Yan Z.; Diao W.; Zhang Q.; Kang Y.; Li J.; Li X.; Sun X.","Yang, Zhujun (57252814800); Yan, Zhiyuan (57202787748); Diao, Wenhui (56816620400); Zhang, Qiang (57463075400); Kang, Yuzhuo (57361932700); Li, Junxi (57324004700); Li, Xinming (57221872527); Sun, Xian (34875643000)","57252814800; 57202787748; 56816620400; 57463075400; 57361932700; 57324004700; 57221872527; 34875643000","Label Propagation and Contrastive Regularization for Semisupervised Semantic Segmentation of Remote Sensing Images","2023","10.1109/TGRS.2023.3277203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161266177&doi=10.1109%2fTGRS.2023.3277203&partnerID=40&md5=ecf257247dc553d8ffcef4ea1fdd6a7c","Remarkable progress based on deep neural networks has been achieved in the semantic segmentation of remote sensing images (RSIs). However, pixel-level labeling is expensive for RSIs. Semisupervised semantic segmentation becomes an alternative approach to reduce the cost of annotation, and it is crucial to utilize efficiently a large number of unlabeled data. Nevertheless, inevitably, there is an unbalanced class distribution between labeled and unlabeled data in a remote sensing scene. Existing semisupervised methods train unlabeled images in isolation from labeled images and only learn reliable pixel pseudo-labels, leading to underutilization of unlabeled images. This article proposes a novel semisupervised semantic segmentation approach based on label propagation and contrastive regularization for RSIs. Specifically, the unlabeled images are augmented by randomly copy-pasting the class regions from labeled images. A prototype feature constraint module is used to enforce the constraint on the pixel features of unlabeled images relying on the prototype features from labeled images, achieving feature alignment on the entire dataset. Furthermore, we present the region contrastive learning (RCL) module that guides the model to learn feature consistency under different perturbations and compact feature representations over class regions on unlabeled images. Extensive experimental results on multiple remote sensing datasets demonstrate that our proposed approach achieves superior performance compared with state-of-the-art semisupervised semantic segmentation methods.  © 1980-2012 IEEE.","Contrastive regularization; label propagation; remote sensing images (RSIs); semantic segmentation; semisupervised learning (SSL)","Final"
"Wang J.; Ding C.H.Q.; Chen S.; He C.; Luo B.","Wang, Jiaxin (57219782521); Ding, Chris H. Q. (7202622028); Chen, Sibao (9734673000); He, Chenggang (57219776672); Luo, Bin (57203411639)","57219782521; 7202622028; 9734673000; 57219776672; 57203411639","Semi-supervised remote sensing image semantic segmentation via consistency regularization and average update of pseudo-label","2020","10.3390/rs12213603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095409394&doi=10.3390%2frs12213603&partnerID=40&md5=cf3a392cae00b78fba5c9ab1011d3b1c","Image segmentation has made great progress in recent years, but the annotation required for image segmentation is usually expensive, especially for remote sensing images. To solve this problem, we explore semi-supervised learning methods and appropriately utilize a large amount of unlabeled data to improve the performance of remote sensing image segmentation. This paper proposes a method for remote sensing image segmentation based on semi-supervised learning. We first design a Consistency Regularization (CR) training method for semi-supervised training, then employ the new learned model for Average Update of Pseudo-label (AUP), and finally combine pseudo labels and strong labels to train semantic segmentation network. We demonstrate the effectiveness of the proposed method on three remote sensing datasets, achieving better performance without more labeled data. Extensive experiments show that our semi-supervised method can learn the latent information from the unlabeled data to improve the segmentation performance. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Consistency training; Pseudo label; Remote sensing image segmentation; Semi-supervised learning","Final"
"Scherer S.; Brehm S.; Lienhart R.","Scherer, Sebastian (57218713282); Brehm, Stephan (57194721743); Lienhart, Rainer (7004444515)","57218713282; 57194721743; 7004444515","Consistency Regularization for Unsupervised Domain Adaptation in Semantic Segmentation","2022","10.1007/978-3-031-06427-2_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130941756&doi=10.1007%2f978-3-031-06427-2_42&partnerID=40&md5=789d245d179e4f5a2582728cf0bf20ba","Unsupervised domain adaptation is a promising technique for computer vision tasks, especially when annotating large amounts of data is very costly and time-consuming, as in semantic segmentation. Here it is attractive to train neural networks on simulated data and fit them to real data on which the models are to be used. In this paper, we propose a consistency regularization method for domain adaptation in semantic segmentation that combines pseudo-labels and strong perturbations. We analyse the impact of two simple perturbations, dropout and image mixing, and show how they contribute enormously to the final performance. Experiments and ablation studies demonstrate that our simple approach achieves strong results on relevant synthetic-to-real domain adaptation benchmarks. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Domain adaptation; Semantic segmentation; Semi-supervised learning; Synthetic data; Unsupervised learning","Final"
"Yin J.; Yan S.; Chen T.; Chen Y.; Yao Y.","Yin, Jianjian (57960359000); Yan, Shuai (57219092953); Chen, Tao (57221072167); Chen, Yi (8630639600); Yao, Yazhou (57072144300)","57960359000; 57219092953; 57221072167; 8630639600; 57072144300","Class Probability Space Regularization for semi-supervised semantic segmentation","2024","10.1016/j.cviu.2024.104146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203835331&doi=10.1016%2fj.cviu.2024.104146&partnerID=40&md5=0b67008c01b0ab8335a2ffeff987c421","Semantic segmentation achieves fine-grained scene parsing in any scenario, making it one of the key research directions to facilitate the development of human visual attention mechanisms. Recent advancements in semi-supervised semantic segmentation have attracted considerable attention due to their potential in leveraging unlabeled data. However, existing methods only focus on exploring the knowledge of unlabeled pixels with high certainty prediction. Their insufficient mining of low certainty regions of unlabeled data results in a significant loss of supervisory information. Therefore, this paper proposes the Class Probability Space Regularization (CPSR) approach to further exploit the potential of each unlabeled pixel. Specifically, we first design a class knowledge reshaping module to regularize the probability space of low certainty pixels, thereby transforming them into high certainty ones for supervised training. Furthermore, we propose a tail probability suppression module to suppress the probabilities of tailed classes, which facilitates the network to learn more discriminative information from the class probability space. Extensive experiments conducted on the PASCAL VOC2012 and Cityscapes datasets prove that our method achieves state-of-the-art performance without introducing much computational overhead. Code is available at https://github.com/MKSAQW/CPSR. © 2024 Elsevier Inc.","Class knowledge reshaping; Class probability space regularization; Human visual attention mechanisms; Semi-supervised semantic segmentation; Tail probability suppression","Final"
"Wang J.; He J.; Liu Y.; Chen C.; Zhang M.; Tan H.","Wang, Jingyi (58920050900); He, Jingyang (59322971600); Liu, Yu (57203675793); Chen, Chen (55858302300); Zhang, Maojun (16033521000); Tan, Hanlin (56727161800)","58920050900; 59322971600; 57203675793; 55858302300; 16033521000; 56727161800","Multi-Scale Classification and Contrastive Regularization: Weakly Supervised Large-Scale 3D Point Cloud Semantic Segmentation","2024","10.3390/rs16173319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203634510&doi=10.3390%2frs16173319&partnerID=40&md5=b5ab95a90b5428883932883b02d7fe39","With the proliferation of large-scale 3D point cloud datasets, the high cost of per-point annotation has spurred the development of weakly supervised semantic segmentation methods. Current popular research mainly focuses on single-scale classification, which fails to address the significant feature scale differences between background and objects in large scenes. Therefore, we propose MCCR (Multi-scale Classification and Contrastive Regularization), an end-to-end semantic segmentation framework for large-scale 3D scenes under weak supervision. MCCR first aggregates features and applies random downsampling to the input data. Then, it captures the local features of a random point based on multi-layer features and the input coordinates. These features are then fed into the network to obtain the initial and final prediction results, and MCCR iteratively trains the model using strategies such as contrastive learning. Notably, MCCR combines multi-scale classification with contrastive regularization to fully exploit multi-scale features and weakly labeled information. We investigate both point-level and local contrastive regularization to leverage point cloud augmentor and local semantic information and introduce a Decoupling Layer to guide the loss optimization in different spaces. Results on three popular large-scale datasets, S3DIS, SemanticKITTI and SensatUrban, demonstrate that our model achieves state-of-the-art (SOTA) performance on large-scale outdoor datasets with only 0.1% labeled points for supervision, while maintaining strong performance on indoor datasets. © 2024 by the authors.","large-scale point clouds; semantic segmentation; weak supervision","Final"
"Li M.; Xie Y.; Shen Y.; Ke B.; Qiao R.; Ren B.; Lin S.; Ma L.","Li, Mengtian (59447381900); Xie, Yuan (55710277800); Shen, Yunhang (56431616600); Ke, Bo (57962164300); Qiao, Ruizhi (57210584624); Ren, Bo (57217481712); Lin, Shaohui (57191847788); Ma, Lizhuang (8930473900)","59447381900; 55710277800; 56431616600; 57962164300; 57210584624; 57217481712; 57191847788; 8930473900","HybridCR: Weakly-Supervised 3D Point Cloud Semantic Segmentation via Hybrid Contrastive Regularization","2022","10.1109/CVPR52688.2022.01451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137703525&doi=10.1109%2fCVPR52688.2022.01451&partnerID=40&md5=2f45d40484b37390355155efeea7ad2f","To address the huge labeling cost in large-scale point cloud semantic segmentation, we propose a novel hybrid contrastive regularization (HybridCR) framework in weakly-supervised setting, which obtains competitive performance compared to its fully-supervised counterpart. Specifically, HybridCR is the first framework to leverage both point consistency and employ contrastive regularization with pseudo labeling in an end-to-end manner. Fundamentally, HybridCR explicitly and effectively considers the semantic similarity between local neighboring points and global characteristics of 3D classes. We further design a dynamic point cloud augmentor to generate diversity and robust sample views, whose transformation parameter is jointly optimized with model training. Through extensive experiments, HybridCR achieves significant performance improvement against the SOTA methods on both indoor and outdoor datasets, e.g., S3DIS, ScanNet-V2, Semantic3D, and SemanticKITTI. © 2022 IEEE.","Computer vision for social good; grouping and shape analysis; Segmentation; Self-& semi-& meta- Transfer/low-shot/long-tail learning","Final"
"Ye P.; Li B.; Chen T.; Fan J.; Mei Z.; Lin C.; Zuo C.; Chi Q.; Ouyang W.","Ye, Peng (58866118000); Li, Baopu (15843770500); Chen, Tao (57192810199); Fan, Jiayuan (56428257800); Mei, Zhen (57849328100); Lin, Chen (57208439048); Zuo, Chongyan (57222808365); Chi, Qinghua (55324006600); Ouyang, Wanli (27068028000)","58866118000; 15843770500; 57192810199; 56428257800; 57849328100; 57208439048; 57222808365; 55324006600; 27068028000","Efficient Joint-Dimensional Search with Solution Space Regularization for Real-Time Semantic Segmentation","2022","10.1007/s11263-022-01663-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136995086&doi=10.1007%2fs11263-022-01663-z&partnerID=40&md5=ab72fca34195aeb1093b404f9e8fe157","Semantic segmentation is a popular research topic in computer vision, and many efforts have been made on it with impressive results. In this paper, we intend to search an optimal network structure that can run in real-time for this problem. Towards this goal, we jointly search the depth, channel, dilation rate and feature spatial resolution, which results in a search space consisting of about 2.78 × 10 324 possible choices. To handle such a large search space, we leverage differential architecture search methods. However, the architecture parameters searched using existing differential methods need to be discretized, which causes the discretization gap between the architecture parameters found by the differential methods and their discretized version as the final solution for the architecture search. Hence, we relieve the problem of discretization gap from the innovative perspective of solution space regularization. Specifically, a novel Solution Space Regularization (SSR) loss is first proposed to effectively encourage the supernet to converge to its discrete one. Then, a new Hierarchical and Progressive Solution Space Shrinking method is presented to further achieve high efficiency of searching. In addition, we theoretically show that the optimization of SSR loss is equivalent to the L-norm regularization, which accounts for the improved search-evaluation gap. Comprehensive experiments show that the proposed search scheme can efficiently find an optimal network structure that yields an extremely fast speed (175 FPS) of segmentation with a small model size (1 M) while maintaining comparable accuracy. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Joint-Dimensional Search; Real-Time Segmentation; Solution Space Regularization","Final"
"Xiao Z.; Zong J.; Lan H.; Wei X.; Tang X.","Xiao, Zhenjiu (57674161400); Zong, Jiaxu (57674424000); Lan, Hai (59051605500); Wei, Xian (56304291000); Tang, Xiaoliang (56327158000)","57674161400; 57674424000; 59051605500; 56304291000; 56327158000","Image semantic segmentation based on manifold regularization constraint; [流形正则化约束的图像语义分割]","2022","10.11834/jig.200527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129717656&doi=10.11834%2fjig.200527&partnerID=40&md5=ab75d80c32de6a3d26ea5751b6a843c7","Objective: Image semantic segmentation is one of the essential issues in computer vision and image processing. It aims to divide pixels in the image into different categories semantically, and to foresee pixel-level predictions. It has been widely used in various fields, such as scene information understanding, automatic driving and medical assisting diagnosis. Competitive performance has still suffered from challenges such as low contrast, uneven luminance and complicated scenarios currently. The performance of semantic segmentation algorithms have mainly constrained by the spatial context information. Current methods based on deep learning algorithms for image semantic segmentation has focused on harnessing the context information between pixels. For instance, the attention mechanism builds an element-wise weight matrix to capture the similarity between pixels which can be used as coefficient to summate the input. Meanwhile, probabilistic graphical models have been utilized in the spatial context as prior to enhance the classification confidence. However, these methodologies require massive computational resource (e.g. GPU memory). A contextual information capturing method is demonstrated based on manifold regularization. By assuming the data in the input image and the segmentation prediction share the same locally geometric structure in the low-dimensional manifold, this research illustrated possibility to harness the relevancy among pixels in more efficient way. As a result, the novel algorithm based on manifold regularization is issued to exploit the spatial context relation from a geometric perspective, which can be embedded into the deep learning framework to improve the performance with no increasing on both parameter amount and reasoning time. Method: The contextual information analysis in the image can be effectively captured by manifold regularization. The DeepLab-v3 architecture is extracted the image features, which uses the residual network(ResNet) as the backbone network. The last two down-sampling layers of the model are pruned, and dilated convolution is employed in the subsequent convolutional layer to control the resolution of the features. For the methodology of regular segmentation, the cross-entropy of single pixel between prediction and ground truth is only involved in the cost function and sum up in total loss without any context information simply. A detailed manifold regularization penalty designation is integrated to single pixel information and the neighborhood context information. This geometric intuition for the initial image data has the same locally geometric shape with those in the segmented result. It indicates that the correspondences between clusters of data points in the input image and output result data points. For instance, when the distance of two input data points in the manifold sub-space is close, the corresponding segmentation result data points are close, and vice versa. Furthermore, the image into sub-image patches to capture the relationship between to customize the constraints between pixels. The hierarchical manifold regularization constraints are achieved via sub-image patch divides into different sizes. When the patch size is minimized, the constraint is between pixels substantially and the approach acts like other pixel-wise context aware algorithms such as fully connected conditional random field (CRF) model. On the contrary, the maximum patch size which equals to the input image size makes the approach become semi-supervised learning algorithm based on interconnected samples. The analyzed model gets improved on segmentation accuracy and achieves state-of-the-art performance. This model is based on two public datasets, Cityscapes and PASCAL VOC 2012 (pattern analysis, statistical modeling and computational learning visual object classes 2012). The performance is measured via mean intersection-over-union (mIoU) averaged across all the classes. The open source toolbox Pytorch is used to build the model. The stochastic gradient descent (SGD) method is adopted as the optimization. In addition, data augmentation is conducted by means of random cropping and inversion in accordance with probability levels. The operating system of the experimental platform is Centos7, with a GPU of model NVIDIA RTX 2080Ti and a CPU of Intel(R) Core(TM) i7-6850. Result: The tests are conducted with the effect of manifold regularization. The algorithm achieves a good accuracy of the segmentation model without increasing computational complexity in the process of model implementation. On the benchmark, the ResNet50 backbone model improves the performance by 0.8% with manifold regularization adopted on the PASCAL VOC 2012 dataset, while the ResNet101 backbone models bring 2.1% mIoU gain. These results demonstrated that the manifold regularization get qualified performance with larger network model, and the analyszed results on the Cityscapes dataset also prove this inference, the ResNet50 model increases by 0.3% while the ResNet101 model increases by 0.5%. With the comparison of other context aggregation methods, we achieve mIoU of 78.0% on the Cityscapes dataset and 69.5% on the PASCAL VOC 2012 dataset. Furthermore, visualization of the segmentation results is implemented. The generated segmentation results are more accurate at the edges and have less error rate based on the algorithm with manifold regularization constraints. Conclusion: This demonstration illustrates a novel algorithm for the context information image semantic segmentation via the manifold regularization constraints, which can be melted into the deep learning network model to improve the segmentation performance without changing the network structure. The results verify that the illustrated algorithm has good generalization capability in semantic segmentation. © 2022, Editorial Office of Journal of Image and Graphics. All right reserved.","Capture of contextual information; Deep learning; Manifold regularization; Residual network(ResNet); Semantic segmentation","Final"
"Fu D.; Nelson B.J.","Fu, Deqing (58317720600); Nelson, Bradley J. (57211353582)","58317720600; 57211353582","Topological Regularization for Dense Prediction","2022","10.1109/ICMLA55696.2022.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152214949&doi=10.1109%2fICMLA55696.2022.00014&partnerID=40&md5=f0e22a1fd04574f71cde14f726d18568","Dense prediction tasks such as depth perception and semantic segmentation are important applications in computer vision that have a concrete topological description in terms of partitioning an image into connected components or estimating a function with a small number of local extrema corresponding to objects in the image. We develop a form of topological regularization based on persistent homology that can be used in dense prediction tasks with these topological descriptions. Experimental results show that the output topology can also appear in the internal activations of trained neural networks which allows for a novel use of topological regularization to the internal states of neural networks during training, reducing the computational cost of the regularization. We demonstrate that this topological regularization of internal activations leads to improved convergence and test benchmarks on several problems and architectures.  © 2022 IEEE.","Computational topology; Monocular depth estimation; Persistent homology; Semantic segmentation; Topological data analysis","Final"
"Barbato F.; Toldo M.; Michieli U.; Zanuttigh P.","Barbato, Francesco (57223755205); Toldo, Marco (57219630564); Michieli, Umberto (57205564138); Zanuttigh, Pietro (6503908255)","57223755205; 57219630564; 57205564138; 6503908255","Latent space regularization for unsupervised domain adaptation in semantic segmentation","2021","10.1109/CVPRW53098.2021.00318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113498521&doi=10.1109%2fCVPRW53098.2021.00318&partnerID=40&md5=c8e2126e71cf5ae958ed69ce028c471b","Deep convolutional neural networks for semantic segmentation achieve outstanding accuracy, however they also have a couple of major drawbacks: first, they do not generalize well to distributions slightly different from the one of the training data; second, they require a huge amount of labeled data for their optimization. In this paper, we introduce feature-level space-shaping regularization strategies to reduce the domain discrepancy in semantic segmentation. In particular, for this purpose we jointly enforce a clustering objective, a perpendicularity constraint and a norm alignment goal on the feature vectors corresponding to source and target samples. Additionally, we propose a novel measure able to capture the relative efficacy of an adaptation strategy compared to supervised training. We verify the effectiveness of such methods in the autonomous driving setting achieving state-of-the-art results in multiple synthetic-to-real road scenes benchmarks. © 2021 IEEE.","","Final"
"Xu Y.; Ghamisi P.","Xu, Yonghao (57199421344); Ghamisi, Pedram (53663404300)","57199421344; 53663404300","Consistency-Regularized Region-Growing Network for Semantic Segmentation of Urban Scenes with Point-Level Annotations","2022","10.1109/TIP.2022.3189825","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135596412&doi=10.1109%2fTIP.2022.3189825&partnerID=40&md5=ad2fc1fa2bb33350da7361bb0e1e6a2a","Deep learning algorithms have obtained great success in semantic segmentation of very high-resolution (VHR) remote sensing images. Nevertheless, training these models generally requires a large amount of accurate pixel-wise annotations, which is very laborious and time-consuming to collect. To reduce the annotation burden, this paper proposes a consistency-regularized region-growing network (CRGNet) to achieve semantic segmentation of VHR remote sensing images with point-level annotations. The key idea of CRGNet is to iteratively select unlabeled pixels with high confidence to expand the annotated area from the original sparse points. However, since there may exist some errors and noises in the expanded annotations, directly learning from them may mislead the training of the network. To this end, we further propose the consistency regularization strategy, where a base classifier and an expanded classifier are employed. Specifically, the base classifier is supervised by the original sparse annotations, while the expanded classifier aims to learn from the expanded annotations generated by the base classifier with the region-growing mechanism. The consistency regularization is thereby achieved by minimizing the discrepancy between the predictions from both the base and the expanded classifiers. We find such a simple regularization strategy is yet very useful to control the quality of the region-growing mechanism. Extensive experiments on two benchmark datasets demonstrate that the proposed CRGNet significantly outperforms the existing state-of-the-art methods. Codes and pre-trained models are available online (https://github.com/YonghaoXu/CRGNet).  © 1992-2012 IEEE.","convolutional neural network (CNN); remote sensing; Semantic segmentation; sparse annotation; very high-resolution (VHR) images; weakly supervised learning","Final"
"Deng Z.; Tang X.; Zhang Z.; Xie J.; Zhang W.","Deng, Zhanhao (58934330300); Tang, Xu (58928116000); Zhang, Zejun (56020887700); Xie, Jianxiao (57200181174); Zhang, Weichuan (52464730200)","58934330300; 58928116000; 56020887700; 57200181174; 52464730200","Class-Aware Feature Regularization for Semantic Segmentation","2023","10.1145/3633637.3633694","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187555135&doi=10.1145%2f3633637.3633694&partnerID=40&md5=5e7225b016942072a965e021f69d1527","In this paper, to address the problem of intra-class consistency and inter-class variation in the deep convolutional neural network (CNN) based methods for semantic segmentation of images, we propose a class-aware feature regularization strategy to revise the features extracted by a deep convolutional neural network, without any change of the original network structure. A pixel-context similarity term is proposed to measure the consistency between feature vectors of pixels and class centers, which guarantees the intra-class consistency of pixels in the interior of an object and is supervised by a One-Hot label to preserve the inter-class variation of different objects. Based on the similarity term, we design a lightweight and efficient plug-in loss term to ensure that the features yielded by a deep CNN possess the quality of intra-class consistency and inter-class variation. As our ideal can be fulfilled effectively by the proposed plug-in loss term, we can simply incorporate it into a CNN-based segmentation model without changing the model structure. The effectiveness of the proposed strategy is proved by incorporating the loss term into some state-of-the-art segmentation models on Cityscapes and ADE20K datasets. © 2023 ACM.","class-aware regularization; inter-class variation; intra-class consistency; semantic segmentation","Final"
"Veksler O.","Veksler, Olga (6602934119)","6602934119","Regularized Loss for Weakly Supervised Single Class Semantic Segmentation","2020","10.1007/978-3-030-58526-6_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093072071&doi=10.1007%2f978-3-030-58526-6_21&partnerID=40&md5=39b868b8e8df5b6e4b09d6638bc7ad9b","Fully supervised semantic segmentation is highly successful, but obtaining dense ground truth is expensive. Thus there is an increasing interest in weakly supervised approaches. We propose a new weakly supervised method for training CNNs to segment an object of a single class of interest. Instead of ground truth, we guide training with a regularized loss function. Regularized loss models prior knowledge about the likely object shape properties and thus guides segmentation towards the more plausible shapes. Training CNNs with regularized loss is difficult. We develop an annealing strategy that is crucial for successful training. The advantage of our method is simplicity: we use standard CNN architectures and intuitive and computationally efficient loss function. Furthermore, we apply the same loss function for any task/dataset, without any tailoring. We first evaluate our approach for salient object segmentation and co-segmentation. These tasks naturally involve one object class of interest. In some cases, our results are only a few points of standard performance measure behind those obtained training the same CNN with full supervision, and state-of-the art results in weakly supervised setting. Then we adapt our approach to weakly supervised multi-class semantic segmentation and obtain state-of-the-art results. © 2020, Springer Nature Switzerland AG.","","Final"
"Lu Y.; Zhang Y.; Cui Z.; Long W.; Chen Z.","Lu, Yujie (59373539900); Zhang, Yongjun (55739754700); Cui, Zhongwei (56102364800); Long, Wei (57216312487); Chen, Ziyang (58997839300)","59373539900; 55739754700; 56102364800; 57216312487; 58997839300","Multi-Dimensional Manifolds Consistency Regularization for semi-supervised remote sensing semantic segmentation","2024","10.1016/j.knosys.2024.112032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195177598&doi=10.1016%2fj.knosys.2024.112032&partnerID=40&md5=70bced01f5c73d402b393ac880f76837","Semi-supervised semantic segmentation in remote sensing is critical for urban planning, environmental monitoring and disaster response. The high cost and time required for high-quality data annotation limits its wider application. Traditional semi-supervised deep learning methods, which operate in a single dimension, limit model robustness and generalization. Our study addresses this issue by proposing an effective semi-supervised learning method. This method improves model robustness and generalization in remote sensing semantic segmentation. We introduce the Multi-Dimensional Manifolds Consistency Regularization (MDMCR) approach. It applies multi-dimensional perturbations to input images and features, expanding the sample library and improving learning efficiency. Our method has been rigorously tested on various datasets. With only 1/8 of the data labeled, it achieved mean Intersection over Union (mIoU) scores of 74.48% on ISPRS Vaihingen and 78.80% on Potsdam. With only 5% labeled data, it reached 49.93% mIoU on DeepGlobe Roads and 57.90% on Massachusetts Roads. These results show the superiority of our method over existing techniques. © 2024","Consistency regularization; Manifold hypothesis; Multi-dimensional manifolds; Semi-supervised remote sensing semantic segmentation","Final"
"Huang Y.; Kang D.; Chen L.; Zhe X.; Jia W.; Bao L.; He X.","Huang, Ye (57208822807); Kang, Di (57202841234); Chen, Liang (57059516200); Zhe, Xuefei (57193646927); Jia, Wenjing (7202412193); Bao, Linchao (55613500900); He, Xiangjian (7404409118)","57208822807; 57202841234; 57059516200; 57193646927; 7202412193; 55613500900; 7404409118","CAR: Class-Aware Regularizations for Semantic Segmentation","2022","10.1007/978-3-031-19815-1_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142692842&doi=10.1007%2f978-3-031-19815-1_30&partnerID=40&md5=af29d5452884ae21f2651b9b79798620","Recent segmentation methods, such as OCR and CPNet, utilizing “class level” information in addition to pixel features, have achieved notable success for boosting the accuracy of existing network modules. However, the extracted class-level information was simply concatenated to pixel features, without explicitly being exploited for better pixel representation learning. Moreover, these approaches learn soft class centers based on coarse mask prediction, which is prone to error accumulation. In this paper, aiming to use class level information more effectively, we propose a universal Class-Aware Regularization (CAR) approach to optimize the intra-class variance and inter-class distance during feature learning, motivated by the fact that humans can recognize an object by itself no matter which other objects it appears with. Three novel loss functions are proposed. The first loss function encourages more compact class representations within each class, the second directly maximizes the distance between different class centers, and the third further pushes the distance between inter-class centers and pixels. Furthermore, the class center in our approach is directly generated from ground truth instead of from the error-prone coarse prediction. Our method can be easily applied to most existing segmentation models during training, including OCR and CPNet, and can largely improve their accuracy at no additional inference overhead. Extensive experiments and ablation studies conducted on multiple benchmark datasets demonstrate that the proposed CAR can boost the accuracy of all baseline models by up to 2.23% mIOU with superior generalization ability. The complete code is available at https://github.com/edwardyehuang/CAR. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Class-aware regularizations; Semantic segmentation","Final"
"Wang Z.; Geng Y.; Jia L.; Qin Y.; Chai Y.; Tong L.; Liu K.","Wang, Zhipeng (56472477200); Geng, Yixuan (57218161203); Jia, Limin (7201396387); Qin, Yong (7403100638); Chai, Yuanyuan (24921220400); Tong, Lei (55413536300); Liu, Keyan (57486393000)","56472477200; 57218161203; 7201396387; 7403100638; 24921220400; 55413536300; 57486393000","Self-Attentive Local Aggregation Learning With Prototype Guided Regularization for Point Cloud Semantic Segmentation of High-Speed Railways","2023","10.1109/TITS.2023.3281352","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161473348&doi=10.1109%2fTITS.2023.3281352&partnerID=40&md5=fc0088b4dad6f8ab51ae7d5595507cb8","Point cloud semantic segmentation for railway infrastructures is an essential step towards establishing railway digital twins. Deep learning-based methods have shown great potential in this field compared to traditional methods that rely on hand-crafted features. However, deep learning-based methods for railway point clouds still face typical challenges that need to be addressed. In this regard, we propose a novel learning framework named SALAProNet, which consists of a set of effective and concise modular solutions. The first challenge addressed is the massive data scale of railway point clouds, which makes it difficult to directly process large-scale point clouds due to memory limitations. To solve this problem, we adapt efficient random sampling in the network and propose the Self-Attentive Aggregation (SAA) module based on an attention mechanism to greatly expand the receptive field, which covers the unsampled points and successfully retains information in a high-dimensional feature space. The second challenge is fine-grained segmentation, where we propose the Local Geometry Embedding (LGE) module to embed local geometry. With the help of context information provided by SAA, the network can perform fine-grained segmentation for railway infrastructures. The third challenge is the insufficient generalization ability of the network, where we propose a Prototype Guided Regularization (PGR) method to guide the network to segment the point cloud among railways with different construction standards. This method enhances the network's interpretability and improves its generalization ability. We have validated our proposed framework through experiments on different datasets, and it outperforms state-of-the-art approaches.  © 2000-2011 IEEE.","Attention mechanism; digital twin; high-speed railway; infrastructure; point cloud semantic segmentation; prototype guided regularization","Final"
"Guan D.; Huang J.; Xiao A.; Lu S.","Guan, Dayan (57202644096); Huang, Jiaxing (57219508311); Xiao, Aoran (57219688834); Lu, Shijian (8439329200)","57202644096; 57219508311; 57219688834; 8439329200","Unbiased Subclass Regularization for Semi-Supervised Semantic Segmentation","2022","10.1109/CVPR52688.2022.00973","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138634592&doi=10.1109%2fCVPR52688.2022.00973&partnerID=40&md5=591d10996091ee6d7862f0f83ee7c5e6","Semi-supervised semantic segmentation learns from small amounts of labelled images and large amounts of unlabelled images, which has witnessed impressive progress with the recent advance of deep neural networks. However, it often suffers from severe class-bias problem while exploring the unlabelled images, largely due to the clear pixel-wise class imbalance in the labelled images. This paper presents an unbiased subclass regularization network (USRN) that alleviates the class imbalance issue by learning class-unbiased segmentation from balanced subclass distributions. We build the balanced subclass distributions by clustering pixels of each original class into multiple subclasses of similar sizes, which provide class-balanced pseudo supervision to regularize the class-biased segmentation. In addition, we design an entropy-based gate mechanism to coordinate learning between the original classes and the clustered subclasses which facilitates subclass regularization effectively by suppressing unconfident subclass predictions. Extensive experiments over multiple public benchmarks show that USRN achieves superior performance as compared with the state-of-the-art. © 2022 IEEE.","grouping and shape analysis; Self- & semi- & meta- Segmentation","Final"
"Chen Z.; Xiao S.; Man W.; Wang D.-H.; He Y.; Zhu S.","Chen, Zirong (59344252000); Xiao, Shunxin (57315896900); Man, Wang (55535473800); Wang, Da-Han (57205748503); He, Yifan (59444997300); Zhu, Shunzhi (14038557100)","59344252000; 57315896900; 55535473800; 57205748503; 59444997300; 14038557100","Enhancing Lightweight Remote Sensing Semantic Segmentation via Weak Consistency Regularization","2024","10.1109/IJCNN60899.2024.10651009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205028697&doi=10.1109%2fIJCNN60899.2024.10651009&partnerID=40&md5=3d0853faddce0d1549e35bf785ebacd4","Remote sensing image semantic segmentation has widespread applications in urban planning and land monitoring. In recent years, U-Net and its variant networks have almost dominated the research in the field of semantic segmentation. However, many models pay less attention to computational efficiency, rendering them ineffective in scenarios with computational resource and timeliness constraints, such as autonomous driving and disaster monitoring. To address this issue, we propose the USA-Net (UNet-like with Shifted Axial), a lightweight hybrid model based on convolution and MLP (Multi-Layer Perceptron). Specifically, we design the ST Block (Shift Tokenized Block), which introduces local features into global operations in MLP through spatial shift, and then use ELCM (Efficient Large-kernel Convolution Module) to enlarge the model's receptive field and learn the shape features of objects. Additionally, we propose a new semi-supervised learning framework to further improve the model's generalization performance. On the ISPRS Vaihingen and ISPRS Potsdam datasets, USA-Net significantly outperforms most state-of-the-art methods in terms of segmentation accuracy and efficiency. © 2024 IEEE.","lightweight hybrid model; remote sensing image; semantic segmentation; semi-supervised learning","Final"
"Wu Y.; Liu C.; Chen L.; Zhao D.; Zheng Q.; Zhou H.","Wu, Yulin (57207733369); Liu, Chang (59088042300); Chen, Lei (57188697317); Zhao, Dong (56576806400); Zheng, Qinghe (57193380395); Zhou, Hongchao (55662133600)","57207733369; 59088042300; 57188697317; 56576806400; 57193380395; 55662133600","Perturbation consistency and mutual information regularization for semi-supervised semantic segmentation","2023","10.1007/s00530-022-00931-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131074723&doi=10.1007%2fs00530-022-00931-9&partnerID=40&md5=e916474b88cc3e2100a76c0cd45baeda","Recent semi-supervised learning has attracted much attention by leveraging the hidden structures learned from unlabeled data to reduce the number of required labels in the field of human-centric understanding. Most semi-supervised methods have been proposed to improve the performance of image classification, and their ideas cannot be directly applied to the task of semantic segmentation. In this paper, we propose a semi-supervised model for sematic segmentation named semi-supervised consistency segmentation (SCSeg). The performance gain benefits from two techniques—perturbation consistency and mutual information regularization. Perturbation consistency enforces the output consistency between the uncorrupted and perturbed features. Mutual information regularization adopts a mutual information loss to ensure the spatial consistency of adjacent patches on unlabeled data. The experimental results on Pascal VOC 2012 and Cityscapes datasets widely used in visual understanding tasks demonstrate that the proposed model outperforms the current semi-supervised segmentation methods under varying amounts of labeled data. The proposed model alleviates the pressure of annotation in human-centric practical multimedia applications towards semantic segmentation. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Mutual information; Perturbation consistency; Semantic segmentation; Semi-supervised consistency segmentation (SCSeg); Semi-supervised learning","Final"
"Xu H.-M.; Liu L.; Bian Q.; Yang Z.","Xu, Hai-Ming (57219688503); Liu, Lingqiao (54956172800); Bian, Qiuchen (57933830400); Yang, Zhen (57226173669)","57219688503; 54956172800; 57933830400; 57226173669","Semi-supervised Semantic Segmentation with Prototype-based Consistency Regularization","2022","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143572302&partnerID=40&md5=b357d71828195bd7e5ed8bbed73a2a6d","Semi-supervised semantic segmentation requires the model to effectively propagate the label information from limited annotated images to unlabeled ones. A challenge for such a per-pixel prediction task is the large intra-class variation, i.e., regions belonging to the same class may exhibit a very different appearance even in the same picture. This diversity will make the label propagation hard from pixels to pixels. To address this problem, we propose a novel approach to regularize the distribution of within-class features to ease label propagation difficulty. Specifically, our approach encourages the consistency between the prediction from a linear predictor and the output from a prototype-based predictor, which implicitly encourages features from the same pseudo-class to be close to at least one within-class prototype while staying far from the other between-class prototypes. By further incorporating CutMix operations and a carefully-designed prototype maintenance strategy, we create a semi-supervised semantic segmentation algorithm that demonstrates superior performance over the state-of-the-art methods from extensive experimental evaluation on both Pascal VOC and Cityscapes benchmarks2 © 2022 Neural information processing systems foundation. All rights reserved.","","Final"
"Savitha G.; Girisha S.; Sughosh P.; Shetty D.K.; Balakrishnan J.M.; Paul R.; Naik N.","Savitha, G. (57192418779); Girisha, S. (57210793170); Sughosh, P. (35339944900); Shetty, Dasharathraj K (55578389700); Balakrishnan, Jayaraj Mymbilly (55881941700); Paul, Rahul (57193679977); Naik, Nithesh (57205319450)","57192418779; 57210793170; 35339944900; 55578389700; 55881941700; 57193679977; 57205319450","Consistency Regularization for Semi-Supervised Semantic Segmentation of Flood Regions from SAR Images","2025","10.1109/ACCESS.2025.3526244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214942151&doi=10.1109%2fACCESS.2025.3526244&partnerID=40&md5=3c15fcc0b268f996c38cbc77323ce429","As one of the most powerful natural catastrophes, floods pose serious risks to people's lives, the integrity of infrastructure, and agricultural landscapes, which increases the toll they take on the economy and society. As a result, it becomes essential to continuously monitor these areas of vulnerability in order to support effective disaster response and mitigation efforts. Accurately defining the extent of floods is a problem for traditional flood mapping approaches, which emphasizes the vital need for modern technologies such as Synthetic Aperture Radar (SAR) imaging. Additionally, there is a need to develop computer-aided tools specifically designed for automatically identifying areas that are vulnerable to flooding using SAR data. Nonetheless, the lack of consistent large datasets presents a barrier that prevents these algorithms from progressing and being used in real-world scenarios. For this reason, the present study aims to develop a semi-supervised semantic segmentation algorithm for accurate flood region delineation in SAR data. In particular, the paper proposes labeling unannotated instances of data using a pseudo-label generation strategy. In order to accomplish this, the study suggests using a self-supervised trained teacher model to generate pseudo-labels and speed up the training procedure. The teacher model is then trained with a student model to efficiently extract features from the labeled data. Furthermore, the study presents a new semantic segmentation technique that uses convolutional neural networks to automatically identify flooded areas in SAR images. A comprehensive assessment conducted on publicly available datasets produces promising results. These results confirm the usefulness and possible relevance of the suggested methodology in enhancing efforts related to flood zone identification and management.  © 2013 IEEE.","Flood mapping; SAR images; Semantic segmentation; Semi-supervised learning","Article in press"
"Ma H.; Lin X.; Wu Z.; Yu Y.","Ma, Haoyu (57200302362); Lin, Xiangru (57214458229); Wu, Zifeng (55613421800); Yu, Yizhou (8554163500)","57200302362; 57214458229; 55613421800; 8554163500","Coarse-to-Fine Domain Adaptive Semantic Segmentation with Photometric Alignment and Category-Center Regularization","2021","10.1109/CVPR46437.2021.00404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120723668&doi=10.1109%2fCVPR46437.2021.00404&partnerID=40&md5=f0c24dbf9755b2d83ad8172b9fd692fe","Unsupervised domain adaptation (UDA) in semantic segmentation is a fundamental yet promising task relieving the need for laborious annotation works. However, the domain shifts/discrepancies problem in this task compromise the final segmentation performance. Based on our observation, the main causes of the domain shifts are differences in imaging conditions, called image-level domain shifts, and differences in object category configurations called category-level domain shifts. In this paper, we propose a novel UDA pipeline that unifies image-level alignment and category-level feature distribution regularization in a coarse-to-fine manner. Specifically, on the coarse side, we propose a photometric alignment module that aligns an image in the source domain with a reference image from the target domain using a set of image-level operators; on the fine side, we propose a category-oriented triplet loss that imposes a soft constraint to regularize category centers in the source domain and a self-supervised consistency regularization method in the target domain. Experimental results show that our proposed pipeline improves the generalization capability of the final segmentation model and significantly outperforms all previous state-of-the-arts. © 2021 IEEE","","Final"
"Liu L.; Zong J.; Xiao Z.; Lan H.; Qu H.","Liu, Lamei (57219007937); Zong, Jiaxu (57674424000); Xiao, Zhenjiu (57674161400); Lan, Hai (59051605500); Qu, Haicheng (55567658100)","57219007937; 57674424000; 57674161400; 59051605500; 55567658100","Cross-consistent semantic segmentation algorithm based on manifold regularization; [流形正则化的交叉一致性语义分割算法]","2022","10.11834/jig.210571","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145582347&doi=10.11834%2fjig.210571&partnerID=40&md5=80a68ac743ca8f845d49980a0a0ef7dc","Objective Image semantic segmentation is a pixel-level classification-related issue, which divides each pixel into different categories in the image, which is a sort of extension and expansion of image classification. Its applications have included like scene information understanding, autonomous driving, and clinical diagnosis. However, deep learning models training requires a large amount of labeled data, and obtaining these data is time-consuming and labor-intensive in semantic segmentation. At present, deep semi-supervised learning is focused on to utilize a large amount of unlabeled data and limit the demand for labeled data. However, current methods are challenged for contextual information collection and constraints, and the existing methods for increasing contextual information often increase the network’ s reasoning speed to varying degrees. So, we develop a semi-supervised semantic segmentation method with manifold regularization on the basis of cross-consistency training. Method Our research is assumed that the input data and its corresponding prediction results have the same geometric structure on the low-dimensional manifold surface in the high-dimensional original data space. The geometric data structure is used to construct regularization constraints based on this assumption. First, we design the penalty that a manifold regularization term is integrated to make single pixel information and neighborhood context information. This geometric perception is that the data in the original image have the same locally geometric shape in related to the segmented result. Next, the manifold regularization constraint method mentioned above is combined with the current mainstream semi-supervised and weakly-supervised image segmentation algorithms, which illustrates that our manifold regularization algorithm can well adapt to various different segmentation tasks. In the semi-supervised and weakly-supervised manifold regularization algorithms, a cutting-edged cross-consistency training model is selected as our skeleton network, and the semi-supervised training method of cross-consistency is given different forms of perturbation to the encoder output to strengthen the predictive invariance of the model. We use the open source toolbox Pytorch to build the model. The stochastic gradient descent (SGD) method is adopted as the optimization. The operating system of the experimental platform is Centos7, with a graphics processing unit (GPU) of model NVIDIA RTX 2080Ti and a CPU of Intel (R) Core (TM) i7-6850. Result By adding manifold regularization constraints, the contextual information is captured in the image, the loss of the intrinsic structure caused by the network is reduced forward calculation process, and the accuracy of the algorithm is improved. In order to verify the effectiveness of the algorithm, experiments are based on two different types of semi-supervised and weakly-supervised semantic segmentation. On the pattern analysis, statistical modeling and computational learning visual object classes 2012 (PASCAL VOC 2012) dataset, the semi-supervised semantic segmentation task is improved by 3. 7% compared to the original network. Our weakly supervised semantic segmentation algorithm is improved by 1. 1% compared with the original network. Furthermore, we implement visualization of the segmentation results on different models. It can be found that the segmentation results generated by manifold regularization constraints have more refined edges and less error rate. Conclusion Our algorithm is based on the contextual information through manifold regularization constraints, and is optimized in semi-supervised and weak-supervised tasks without changing the original network structure. The experimental results verify that our algorithm is potential to generalization and optimal ability. © 2022 Chinese Journal of Clinical Pharmacology and Therapeutics. All rights reserved.","cross-consistency training; deep learning; manifold regularization; semantic segmentation; semi-supervised semantic segmentation; weakly-supervised semantic segmentation","Final"
"Rao C.; Fan W.; Yang X.; Wei X.; Zhou D.","Rao, Chaoyu (57748637900); Fan, Wanshu (57206253891); Yang, Xing (59343484200); Wei, Xiaopeng (7402117019); Zhou, Dongsheng (13105639000)","57748637900; 57206253891; 59343484200; 7402117019; 13105639000","BRG: Bidirectional Regularization Guidance for Unsupervised Domain Adaptation Semantic Segmentation","2024","10.1109/IJCNN60899.2024.10651508","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204981719&doi=10.1109%2fIJCNN60899.2024.10651508&partnerID=40&md5=648ad56f09649f3ce0a2a289b9554442","Unsupervised Domain Adaptation Semantic Segmentation (UDASS) aims to harness labeled data from the source domain alongside unlabeled data from the target domain to effectively segment target domain images. While self-training has achieved tremendous success in UDASS, most existing methods heavily rely on source data and lack of sufficient learning from target data, resulting in a performance decline. To address this issue, this paper introduces a Bidirectional Regularization Guidance (BRG) method, which combines a Target Perturbation Consistency (TPC) module and a thing-class ImageNet Feature Distance Reweighting (FDR) module to provide effective regularization guidance. Specifically, the TPC module is introduced to perturb the target stream by masking at the input level and adding feature noise at the feature level. This module employs a target perturbation consistency loss to penalize inconsistencies between perturbed student predictions and teacher model predictions, thereby facilitating improved learning of contextual information by the student model from the target images. To further enhance the model's generalization ability to the target domain, We propose an FDR module that employs a transferability map to calculate a reweighted graph, helping to effectively align source features with ImageNet features by reweighting the feature distances, especially those with lower transferability Through rigorous experimentation in standard UDASS settings - training with synthetic labeled and real unlabeled data - BRG outperforms baseline model on GTAV→Cityscapes and SYNTHIA→Cityscapes. © 2024 IEEE.","Self-training; Semantic Segmentation; Unsupervised Domain Adaptation","Final"
"Huang Y.; Kang D.; Chen L.; Jia W.; He X.; Duan L.; Zhe X.; Bao L.","Huang, Ye (57208822807); Kang, Di (57202841234); Chen, Liang (57059516200); Jia, Wenjing (7202412193); He, Xiangjian (7404409118); Duan, Lixin (57205084445); Zhe, Xuefei (57193646927); Bao, Linchao (55613500900)","57208822807; 57202841234; 57059516200; 7202412193; 7404409118; 57205084445; 57193646927; 55613500900","CARD: Semantic Segmentation with Efficient Class-Aware Regularized Decoder","2024","10.1109/TCSVT.2024.3395132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192186308&doi=10.1109%2fTCSVT.2024.3395132&partnerID=40&md5=5bd5a3d0e76b4ca48fc225779bfabae0","Semantic segmentation has recently achieved notable advances by exploiting 'class-level' contextual information during learning, e.g., the Object Contextual Representation (OCR) and Context Prior (CPNet) approaches. However, these approaches simply concatenate class-level information to pixel features to boost pixel representation learning, which cannot fully utilize intra-class and inter-class contextual information. Moreover, these approaches learn soft class centers based on coarse mask prediction, which is prone to error accumulation. To better exploit class-level information, we propose a universal Class-Aware Regularization (CAR) approach to optimize the intra-class variance and inter-class distance during feature learning, motivated by the fact that humans can recognize an object by itself no matter which other objects it appears with. Moreover, we design a dedicated decoder for CAR (named CARD), which consists of a novel spatial token mixer and an upsampling module, to maximize its gain for existing baselines while being highly efficient in terms of computational cost. Specifically, CAR consists of three novel loss functions. The first loss function encourages more compact class representations within each class, the second directly maximizes the distance between different class centers, and the third further pushes the distance between inter-class centers and pixels. Furthermore, the class center in our approach is directly generated from ground truth instead of from the error-prone coarse prediction. CAR can be directly applied to most existing segmentation models during training, including OCR and CPNet, and can largely improve their accuracy at no additional inference overhead. Extensive experiments and ablation studies conducted on multiple benchmark datasets demonstrate that the proposed CAR can boost the accuracy of all baseline models by up to 2.23% mIOU with superior generalization ability. CARD outperforms state-of-the-art approaches on multiple benchmarks with a highly efficient architecture. The code will be available at https://github.com/edwardyehuang/CAR.  © 1991-2012 IEEE.","cityscapes; COCOStuff; Pascal context; representation learning; Semantic segmentation","Final"
"Chang J.; Pang Y.-T.; Hsu C.-T.","Chang, Jui (57474169700); Pang, Yu-Ting (57474436400); Hsu, Chiou-Ting (57089422600)","57474169700; 57474436400; 57089422600","Towards the Target: Self-regularized Progressive Learning for Unsupervised Domain Adaptation on Semantic Segmentation","2022","10.1007/978-3-031-02375-0_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130359686&doi=10.1007%2f978-3-031-02375-0_22&partnerID=40&md5=b22b0c853a8fc1bdfffd3bbde7289e94","Unsupervised domain adaptation for semantic segmentation aims to transfer the knowledge learned from a labeled synthetic source domain to an unlabeled real-world target domain. The main challenge lies in the difference between the two domains, i.e., the so-called “domain gap”. Although the two domains are supposed to share the same set of class labels, the semantics encoded by the source labels are not always consistent with those of the target data. Some recent efforts have been taken to explore the domain-specific semantics by conducting a within-domain adaptation using the predicted pseudo labels of the target data. The quality of the pseudo labels is therefore essential to the within-domain adaptation. In this paper, we propose a unified framework to progressively facilitate the adaptation towards the target domain. First, we propose to conduct the cross-domain adaptation through a novel source label relaxation. The relaxed labels offer a good trade-off between the source supervision and the target semantics. Next, we propose a dual-level self-regularization to regularize the pseudo-label learning and also to tackle the class-imbalanced issue in the within-domain adaptation stage. The experiment results on two benchmarks, i.e., GTA5 → Cityscapes and SYNTHIA → Cityscapes, show considerable improvement over the strong baseline and demonstrate the superiority of our framework over other methods. © 2022, Springer Nature Switzerland AG.","Class imbalance; Label relaxation; Progressive learning; Self-regularization; Semantic segmentation; Unsupervised domain adaptation","Final"
"Xin Y.; Fan Z.; Qi X.; Geng Y.; Li X.","Xin, Yi (58876657600); Fan, Zide (57453721400); Qi, Xiyu (57998340200); Geng, Ying (58876706400); Li, Xinming (57221872527)","58876657600; 57453721400; 57998340200; 58876706400; 57221872527","Enhancing Semi-Supervised Semantic Segmentation of Remote Sensing Images via Feature Perturbation-Based Consistency Regularization Methods","2024","10.3390/s24030730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184663726&doi=10.3390%2fs24030730&partnerID=40&md5=01a68198c9b360f3a9394cd694d0722c","In the field of remote sensing technology, the semantic segmentation of remote sensing images carries substantial importance. The creation of high-quality models for this task calls for an extensive collection of image data. However, the manual annotation of these images can be both time-consuming and labor-intensive. This has catalyzed the advent of semi-supervised semantic segmentation methodologies. Yet, the complexities inherent within the foreground categories of these remote sensing images present challenges in preserving prediction consistency. Moreover, remote sensing images possess more complex features, and different categories are confused within the feature space, making optimization based on the feature space challenging. To enhance model consistency and to optimize feature-based class categorization, this paper introduces a novel semi-supervised semantic segmentation framework based on Mean Teacher (MT). Unlike the conventional Mean Teacher that only introduces perturbations at the image level, we incorporate perturbations at the feature level. Simultaneously, to maintain consistency after feature perturbation, we employ contrastive learning for feature-level learning. In response to the complex feature space of remote sensing images, we utilize entropy threshold to assist contrastive learning, selecting feature key-values more precisely, thereby enhancing the accuracy of segmentation. Extensive experimental results on the ISPRS Potsdam dataset and the challenging iSAID dataset substantiate the superior performance of our proposed methodology. © 2024 by the authors.","consistency regularization; contrastive learning; feature perturbation; remote sensing; semantic segmentation; semi-supervised learning","Final"
"Ding H.; Zhang H.; Jiang X.","Ding, Henghui (57204513246); Zhang, Hui (57204621393); Jiang, Xudong (16178527100)","57204513246; 57204621393; 16178527100","Self-regularized prototypical network for few-shot semantic segmentation","2023","10.1016/j.patcog.2022.109018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138800807&doi=10.1016%2fj.patcog.2022.109018&partnerID=40&md5=3c0ffd8389d2126c08f2a008e8c75418","The deep CNNs in image semantic segmentation typically require a large number of densely-annotated images for training and have difficulties in generalizing to unseen object categories. Therefore, few-shot segmentation has been developed to perform segmentation with just a few annotated examples. In this work, we tackle the few-shot segmentation using a self-regularized prototypical network (SRPNet) based on prototype extraction for better utilization of the support information. The proposed SRPNet extracts class-specific prototype representations from support images and generates segmentation masks for query images by a distance metric - the fidelity. A direct yet effective prototype regularization on support set is proposed in SRPNet, in which the generated prototypes are evaluated and regularized on the support set itself. The extent to which the generated prototypes restore the support mask imposes an upper limit on performance. The performance on the query set should never exceed the upper limit no matter how complete the knowledge is generalized from support set to query set. With the specific prototype regularization, SRPNet fully exploits knowledge from the support and offers high-quality prototypes that are representative for each semantic class and meanwhile discriminative for different classes. The query performance is further improved by an iterative query inference (IQI) module that combines a set of regularized prototypes. Our proposed SRPNet achieves new state-of-art performance on 1-shot and 5-shot segmentation benchmarks. © 2022","CNN; Few-shot segmentation; Iterative query inference; Non-parametric distance fidelity; Prototype; Prototypical network; Self-regularized; SRPNet","Final"
"Li Q.; Zorzi S.; Shi Y.; Fraundorfer F.; Zhu X.X.","Li, Qingyu (57208661005); Zorzi, Stefano (57214136113); Shi, Yilei (55495784300); Fraundorfer, Friedrich (8977349800); Zhu, Xiao Xiang (55696622200)","57208661005; 57214136113; 55495784300; 8977349800; 55696622200","END-TO-END SEMANTIC SEGMENTATION AND BOUNDARY REGULARIZATION OF BUILDINGS FROM SATELLITE IMAGERY","2021","10.1109/IGARSS47720.2021.9555147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126019562&doi=10.1109%2fIGARSS47720.2021.9555147&partnerID=40&md5=dfb5ca14b19738460fa397c95ce5cea2","Building footprint generation is a vital task of satellite imagery interpretation. However, the segmentation masks of buildings obtained by existing semantic segmentation networks often have blurred boundaries and irregular shapes. In this research, we propose a new boundary regularization network for building footprint generation in satellite images. More specifically, we consider semantic segmentation and boundary regularization in an end-to-end generative adversarial network (GAN). The learned building footprints are regularized by the interplay between the generator and discriminator. By doing so, the straight boundaries and geometric details of the building could be preserved. Experiments are conducted on a collected dataset of Planetscope satellite imagery (spatial resolution: 4.77 m/pixel). Our approach is much superior to the state-of-the-art methods in both quantitative and qualitative results. © 2021 IEEE","Boundary regularization; Building; Generative adversarial network; Satellite imagery; Semantic segmentation","Final"
"Chang Y.-T.; Wang Q.; Hung W.-C.; Piramuthu R.; Tsai Y.-H.; Yang M.-H.","Chang, Yu-Ting (57216947810); Wang, Qiaosong (57195598105); Hung, Wei-Chih (57191431635); Piramuthu, Robinson (6507058219); Tsai, Yi-Hsuan (56112378300); Yang, Ming-Hsuan (7404927015)","57216947810; 57195598105; 57191431635; 6507058219; 56112378300; 7404927015","Mixup-CAM: Weakly-supervised Semantic Segmentation via Uncertainty Regularization","2020","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127015273&partnerID=40&md5=d58d5edb01155d4aec0b326a2a00380a","Obtaining object response maps is one important step to achieve weakly-supervised semantic segmentation using image-level labels. However, existing methods rely on the classification task, which could result in a response map only attending on discriminative object regions as the network does not need to see the entire object for optimizing the classification loss. To tackle this issue, we propose a principled and end-to-end trainable framework to allow the network paying attention to other parts of the object, while producing a more complete and uniform response map. Specifically, we introduce the mixup data augmentation scheme into the classification network and design two uncertainty regularization terms to better interact with the mixup strategy. In experiments, we conduct extensive analysis to demonstrate the proposed method and show favorable performance against state-of-the-art approaches. © 2020. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.","","Final"
"Jin G.; Chen X.; Ying L.","Jin, Ge (57225904229); Chen, Xu (57190005572); Ying, Long (57218709037)","57225904229; 57190005572; 57218709037","Deep Multi-Task Learning for an Autoencoder-Regularized Semantic Segmentation of Fundus Retina Images","2022","10.3390/math10244798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144650420&doi=10.3390%2fmath10244798&partnerID=40&md5=386129856d647dcc8dccd7561b8b2377","Automated segmentation of retinal blood vessels is necessary for the diagnosis, monitoring, and treatment planning of the disease. Although current U-shaped structure models have achieved outstanding performance, some challenges still emerge due to the nature of this problem and mainstream models. (1) There does not exist an effective framework to obtain and incorporate features with different spatial and semantic information at multiple levels. (2) The fundus retina images coupled with high-quality blood vessel segmentation are relatively rare. (3) The information on edge regions, which are the most difficult parts to segment, has not received adequate attention. In this work, we propose a novel encoder–decoder architecture based on the multi-task learning paradigm to tackle these challenges. The shared image encoder is regularized by conducting the reconstruction task in the VQ-VAE (Vector Quantized Variational AutoEncoder) module branch to improve the generalization ability. Meanwhile, hierarchical representations are generated and integrated to complement the input image. The edge attention module is designed to make the model capture edge-focused feature representations via deep supervision, focusing on the target edge regions that are most difficult to recognize. Extensive evaluations of three publicly accessible datasets demonstrate that the proposed model outperforms the current state-of-the-art methods. © 2022 by the authors.","edge attention; retinal vessel segmentation; VQ-VAE","Final"
"Li X.; He Q.; Dai S.; Wu P.; Tong W.","Li, Xiaoqiang (55718219400); He, Qin (57218835653); Dai, Songmin (57214629781); Wu, Pin (8534086200); Tong, Weiqin (7202450909)","55718219400; 57218835653; 57214629781; 8534086200; 7202450909","Semi-Supervised Semantic Segmentation Constrained by Consistency Regularization","2020","10.1109/ICME46284.2020.9102851","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090393264&doi=10.1109%2fICME46284.2020.9102851&partnerID=40&md5=92ada3cec0cd0a8277be24c00f425cb2","In this paper, we propose a self-training based method for semi-supervised semantic segmentation. Our method utilizes k perturbed images of each unlabeled image to generate a new mask through the proposed vote operation which in turn is used as a supervision signal to train the model. The k predicted masks of perturbed images can provide nontrivial knowledge that is not captured by a single prediction and the proposed vote operation enables the model to output a low entropy prediction. Consistency regularization is applied between generated mask and k masks in terms of MSE loss in our network. Extensive experiments are conducted on different datasets to evaluate the effectiveness of our method. We show that the proposed method surpasses previous state-of the-art semi-supervised methods on ISIC 2017 dataset and achieves competitive performance on PASCAL VOC 2012 dataset. © 2020 IEEE.","Consistency regularization; Semantic segmentation; Semi-supervised learning","Final"
"Su W.; Wang Z.","Su, Wen (57015989700); Wang, Zengfu (35276043300)","57015989700; 35276043300","Regularized fully convolutional networks for RGB-D semantic segmentation","2017","10.1109/VCIP.2016.7805508","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011060256&doi=10.1109%2fVCIP.2016.7805508&partnerID=40&md5=1063a274ce66afc05d4a44f4d9bb4c30","The prospect of semantic segmentation using depth is alluring. In most of the previous work features are only combined by using simple classification strategies. The inter-feature and inter-label relationships have been ignored. This paper proposes a novel unified framework for RGB-D semantic segmentation. We use regularized fully convolutional networks whose inputs are depth map and hand-crafted features. Relationships between those features and their labels are learnt and utilized by rigorously imposing regularization in fully connected layers. The regularized fully convolutional networks can be efficiently launched using a GPU implementation at an affordable training cost. Experiments demonstrate that our regularized fully convolutional networks taking features as inputs obtain competitive results on the PASCAL VOC 2011 dataset and NYUDv2. © 2016 IEEE.","Depth Segmentation FCN Features Regularization","Final"
