"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"End-to-End Semantic Segmentation and Boundary Regularization of Buildings from Satellite Imagery","Q. Li; S. Zorzi; Y. Shi; F. Fraundorfer; X. X. Zhu","Data Science in Earth Observation, Technical University of Munich (TUM), Munich, Germany; Institute of Computer Graphics and Vision, Graz University of Technology (TU Graz), Graz, Austria; Remote Sensing Technology, Technical University of Munich (TUM), Munich, Germany; Institute of Computer Graphics and Vision, Graz University of Technology (TU Graz), Graz, Austria; Data Science in Earth Observation, Technical University of Munich (TUM), Munich, Germany",2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS,"12 Oct 2021","2021","","","2508","2511","Building footprint generation is a vital task of satellite imagery interpretation. However, the segmentation masks of buildings obtained by existing semantic segmentation networks often have blurred boundaries and irregular shapes. In this research, we propose a new boundary regularization network for building footprint generation in satellite images. More specifically, we consider semantic segmentation and boundary regularization in an end-to-end generative adversarial network (GAN). The learned building footprints are regularized by the interplay between the generator and discriminator. By doing so, the straight boundaries and geometric details of the building could be preserved. Experiments are conducted on a collected dataset of Planetscope satellite imagery (spatial resolution: 4.77 m/pixel). Our approach is much superior to the state-of-the-art methods in both quantitative and qualitative results.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9555147","European Research Council (ERC)(grant numbers:ERC-2016-StG-714087); Helmholtz Association(grant numbers:VH-NG-1018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555147","semantic segmentation;boundary regularization;building;satellite imagery;generative adversarial network","Image segmentation;Visualization;Satellites;Shape;Buildings;Semantics;Generative adversarial networks","","3","","9","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Semi-Supervised Semantic Segmentation Constrained by Consistency Regularization","X. Li; Q. He; S. Dai; P. Wu; W. Tong","School of Computer Engineering and Science, Shanghai University, China; School of Computer Engineering and Science, Shanghai University, China; School of Computer Engineering and Science, Shanghai University, China; School of Computer Engineering and Science, Shanghai University, China; School of Computer Engineering and Science, Shanghai University, China",2020 IEEE International Conference on Multimedia and Expo (ICME),"9 Jun 2020","2020","","","1","6","In this paper, we propose a self-training based method for semi-supervised semantic segmentation. Our method utilizes k perturbed images of each unlabeled image to generate a new mask through the proposed vote operation which in turn is used as a supervision signal to train the model. The k predicted masks of perturbed images can provide nontrivial knowledge that is not captured by a single prediction and the proposed vote operation enables the model to output a low entropy prediction. Consistency regularization is applied between generated mask and k masks in terms of MSE loss in our network. Extensive experiments are conducted on different datasets to evaluate the effectiveness of our method. We show that the proposed method surpasses previous state-of the-art semi-supervised methods on ISIC 2017 dataset and achieves competitive performance on PASCAL VOC 2012 dataset.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102851","Semi-supervised learning;semantic segmentation;consistency regularization","Image segmentation;Semantics;Entropy;Training;Skin;Prediction algorithms;Lesions","","2","","19","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Semantic Segmentation with Generative Models: Semi-Supervised Learning and Strong Out-of-Domain Generalization","D. Li; J. Yang; K. Kreis; A. Torralba; S. Fidler",NVIDIA; NVIDIA; NVIDIA; MIT; NVIDIA,2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"2 Nov 2021","2021","","","8296","8307","Training deep networks with limited labeled data while achieving a strong generalization ability is key in the quest to reduce human annotation efforts. This is the goal of semi-supervised learning, which exploits more widely available unlabeled data to complement small labeled data sets. In this paper, we propose a novel framework for discriminative pixel-level tasks using a generative model of both images and labels. Concretely, we learn a generative adversarial network that captures the joint image-label distribution and is trained efficiently using a large set of un-labeled images supplemented with only few labeled ones. We build our architecture on top of StyleGAN2 [45], augmented with a label synthesis branch. Image labeling at test time is achieved by first embedding the target image into the joint latent space via an encoder network and test-time optimization, and then generating the label from the inferred embedding. We evaluate our approach in two important domains: medical image segmentation and part-based face segmentation. We demonstrate strong in-domain performance compared to several baselines, and are the first to showcase extreme out-of-domain generalization, such as transferring from CT to MRI in medical imaging, and photographs of real faces to paintings, sculptures, and even cartoons and animal faces. Project Page: https://nv-tlabs.github.io/semanticGAN/","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577499","","Training;Image segmentation;Annotations;Animals;Face recognition;Computational modeling;Semantics","","88","","99","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Consistency-Regularized Region-Growing Network for Semantic Segmentation of Urban Scenes With Point-Level Annotations","Y. Xu; P. Ghamisi","Institute of Advanced Research in Artificial Intelligence (IARAI), Vienna, Austria; Institute of Advanced Research in Artificial Intelligence (IARAI), Vienna, Austria",IEEE Transactions on Image Processing,"2 Aug 2022","2022","31","","5038","5051","Deep learning algorithms have obtained great success in semantic segmentation of very high-resolution (VHR) remote sensing images. Nevertheless, training these models generally requires a large amount of accurate pixel-wise annotations, which is very laborious and time-consuming to collect. To reduce the annotation burden, this paper proposes a consistency-regularized region-growing network (CRGNet) to achieve semantic segmentation of VHR remote sensing images with point-level annotations. The key idea of CRGNet is to iteratively select unlabeled pixels with high confidence to expand the annotated area from the original sparse points. However, since there may exist some errors and noises in the expanded annotations, directly learning from them may mislead the training of the network. To this end, we further propose the consistency regularization strategy, where a base classifier and an expanded classifier are employed. Specifically, the base classifier is supervised by the original sparse annotations, while the expanded classifier aims to learn from the expanded annotations generated by the base classifier with the region-growing mechanism. The consistency regularization is thereby achieved by minimizing the discrepancy between the predictions from both the base and the expanded classifiers. We find such a simple regularization strategy is yet very useful to control the quality of the region-growing mechanism. Extensive experiments on two benchmark datasets demonstrate that the proposed CRGNet significantly outperforms the existing state-of-the-art methods. Codes and pre-trained models are available online (https://github.com/YonghaoXu/CRGNet).","1941-0042","","10.1109/TIP.2022.3189825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9839390","Semantic segmentation;very high-resolution (VHR) images;weakly supervised learning;sparse annotation;convolutional neural network (CNN);remote sensing","Annotations;Image segmentation;Semantics;Training;Remote sensing;Knowledge transfer;Predictive models","Algorithms;Benchmarking;Semantics","26","","54","IEEE","25 Jul 2022","","","IEEE","IEEE Journals"
"Transferring and Regularizing Prediction for Semantic Segmentation","Y. Zhang; Z. Qiu; T. Yao; C. -W. Ngo; D. Liu; T. Mei","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; JD AI Research, Beijing, China; City University of Hong Kong, Kowloon, Hong Kong; University of Science and Technology of China, Hefei, China; JD AI Research, Beijing, China",2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"5 Aug 2020","2020","","","9618","9627","Semantic segmentation often requires a large set of images with pixel-level annotations. In the view of extremely expensive expert labeling, recent research has shown that the models trained on photo-realistic synthetic data (e.g., computer games) with computer-generated annotations can be adapted to real images. Despite this progress, without constraining the prediction on real images, the models will easily overfit on synthetic data due to severe domain mismatch. In this paper, we novelly exploit the intrinsic properties of semantic segmentation to alleviate such problem for model transfer. Specifically, we present a Regularizer of Prediction Transfer (RPT) that imposes the intrinsic properties as constraints to regularize model transfer in an unsupervised fashion. These constraints include patch-level, cluster-level and context-level semantic prediction consistencies at different levels of image formation. As the transfer is label-free and data-driven, the robustness of prediction is addressed by selectively involving a subset of image regions for model regularization. Extensive experiments are conducted to verify the proposal of RPT on the transfer of models trained on GTA5 and SYNTHIA (synthetic data) to Cityscapes dataset (urban street scenes). RPT shows consistent improvements when injecting the constraints on several neural networks for semantic segmentation. More remarkably, when integrating RPT into the adversarial-based segmentation framework, we report to-date the best results: mIoU of 53.2%/51.7% when transferring from GTA5/SYNTHIA to Cityscapes, respectively.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156873","","Semantics;Image segmentation;Roads;Buildings;Visualization;Labeling;Adaptation models","","24","","61","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Learning from Mistakes: Self-Regularizing Hierarchical Representations in Point Cloud Semantic Segmentation","E. Camuffo; U. Michieli; S. Milani","University of Padova, Italy; University of Padova, Italy; University of Padova, Italy",IEEE Transactions on Multimedia,"","2023","PP","99","1","11","Recent advances in autonomous robotic technologies have highlighted the growing need for precise environmental analysis. Point cloud semantic segmentation has gained attention to accomplish fine-grained scene understanding by acting directly on raw content provided by sensors. Recent solutions showed how different learning techniques can be used to improve the performance of the model, without any architectural or dataset change. Following this trend, we present a coarse-to-fine setup that LEArns from classification mistaKes (LEAK) derived from a standard model. First, classes are clustered into macro groups according to mutual prediction errors; then, the learning process is regularized by: (1) aligning class-conditional prototypical feature representation for both fine and coarse classes, (2) weighting instances with a per-class fairness index. Our LEAK approach is very general and can be seamlessly applied on top of any segmentation architecture; indeed, experimental results showed that it enables state-of-the-art performances on different architectures, datasets and tasks, while ensuring more balanced class-wise results and faster convergence.","1941-0077","","10.1109/TMM.2023.3345152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10368362","Point Clouds;Semantic Segmentation;Representation Learning;Spectral Clustering;Prototypes;Fairness","Prototypes;Standards;Semantics;Point cloud compression;Semantic segmentation;Computer architecture;Training","","4","","","CCBY","21 Dec 2023","","","IEEE","IEEE Early Access Articles"
"CARD: Semantic Segmentation With Efficient Class-Aware Regularized Decoder","Y. Huang; D. Kang; L. Chen; W. Jia; X. He; L. Duan; X. Zhe; L. Bao","Shenzhen Institute for Advanced Study, University of Electronic Science and Technology of China, Shenzhen, China; Tencent AI Lab, Shenzhen, China; College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; School of Computer Science, University of Nottingham Ningbo China, Ningbo, China; Shenzhen Institute for Advanced Study, University of Electronic Science and Technology of China, Shenzhen, China; Tencent AI Lab, Shenzhen, China; School of Computer Science, University of Birmingham, Birmingham, U.K.",IEEE Transactions on Circuits and Systems for Video Technology,"30 Oct 2024","2024","34","10","9024","9038","Semantic segmentation has recently achieved notable advances by exploiting “class-level” contextual information during learning, e.g., the Object Contextual Representation (OCR) and Context Prior (CPNet) approaches. However, these approaches simply concatenate class-level information to pixel features to boost pixel representation learning, which cannot fully utilize intra-class and inter-class contextual information. Moreover, these approaches learn soft class centers based on coarse mask prediction, which is prone to error accumulation. To better exploit class-level information, we propose a universal Class-Aware Regularization (CAR) approach to optimize the intra-class variance and inter-class distance during feature learning, motivated by the fact that humans can recognize an object by itself no matter which other objects it appears with. Moreover, we design a dedicated decoder for CAR (named CARD), which consists of a novel spatial token mixer and an upsampling module, to maximize its gain for existing baselines while being highly efficient in terms of computational cost. Specifically, CAR consists of three novel loss functions. The first loss function encourages more compact class representations within each class, the second directly maximizes the distance between different class centers, and the third further pushes the distance between inter-class centers and pixels. Furthermore, the class center in our approach is directly generated from ground truth instead of from the error-prone coarse prediction. CAR can be directly applied to most existing segmentation models during training, including OCR and CPNet, and can largely improve their accuracy at no additional inference overhead. Extensive experiments and ablation studies conducted on multiple benchmark datasets demonstrate that the proposed CAR can boost the accuracy of all baseline models by up to 2.23% mIOU with superior generalization ability. CARD outperforms state-of-the-art approaches on multiple benchmarks with a highly efficient architecture. The code will be available at https://github.com/edwardyehuang/CAR.","1558-2205","","10.1109/TCSVT.2024.3395132","National Natural Science Foundation of China(grant numbers:61901117); Natural Science Foundation of Fujian Province(grant numbers:2023J01083); Shenzhen LongHua Fundamental Research Program(grant numbers:10162A20230325B73A546); OpenI Community (https://openi.pcl.ac.cn); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10510312","Semantic segmentation;representation learning;cityscapes;Pascal context;COCOStuff","Automobiles;Feature extraction;Semantic segmentation;Task analysis;Decoding;Training;Cows","","1","","70","IEEE","29 Apr 2024","","","IEEE","IEEE Journals"
"Topological Regularization for Dense Prediction","D. Fu; B. J. Nelson","Department of Statistics, University of Chicago; Department of Statistics, University of Chicago",2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA),"23 Mar 2023","2022","","","45","52","Dense prediction tasks such as depth perception and semantic segmentation are important applications in computer vision that have a concrete topological description in terms of partitioning an image into connected components or estimating a function with a small number of local extrema corresponding to objects in the image. We develop a form of topological regularization based on persistent homology that can be used in dense prediction tasks with these topological descriptions. Experimental results show that the output topology can also appear in the internal activations of trained neural networks which allows for a novel use of topological regularization to the internal states of neural networks during training, reducing the computational cost of the regularization. We demonstrate that this topological regularization of internal activations leads to improved convergence and test benchmarks on several problems and architectures.","","978-1-6654-6283-9","10.1109/ICMLA55696.2022.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10069898","Computational topology;Topological data analysis;Persistent homology;Monocular depth estimation;Semantic segmentation","Training;Semantic segmentation;Neural networks;Machine learning;Network architecture;Transformers;Topology","","","","55","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"HybridCR: Weakly-Supervised 3D Point Cloud Semantic Segmentation via Hybrid Contrastive Regularization","M. Li; Y. Xie; Y. Shen; B. Ke; R. Qiao; B. Ren; S. Lin; L. Ma","School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China; Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; Tencent Youtu Lab; School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China",2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"27 Sep 2022","2022","","","14910","14919","To address the huge labeling cost in large-scale point cloud semantic segmentation, we propose a novel hybrid contrastive regularization (HybridCR) framework in weakly-supervised setting, which obtains competitive performance compared to its fully-supervised counterpart. Specifically, HybridCR is the first framework to leverage both point consistency and employ contrastive regularization with pseudo labeling in an end-to-end manner. Fundamentally, HybridCR explicitly and effectively considers the semantic similarity between local neighboring points and global characteristics of 3D classes. We further design a dynamic point cloud augmentor to generate diversity and robust sample views, whose transformation parameter is jointly optimized with model training. Through extensive experiments, HybridCR achieves significant performance improvement against the SOTA methods on both indoor and outdoor datasets, e.g., S3DIS, ScanNet-V2, Semantic3D, and SemanticKITTI.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01451","National Key Research and Development Program of China(grant numbers:2019YFC1521104); National Natural Science Foundation of China(grant numbers:72192821,61972157,62102151,62176092); Shanghai Municipal Science and Technology Major Project(grant numbers:2021SHZDZX0102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879771","Computer vision for social good; Segmentation;grouping and shape analysis; Self-& semi-& meta- Transfer/low-shot/long-tail learning","Point cloud compression;Training;Computer vision;Three-dimensional displays;Costs;Shape;Computational modeling","","54","","40","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Coarse-to-Fine Domain Adaptive Semantic Segmentation with Photometric Alignment and Category-Center Regularization","H. Ma; X. Lin; Z. Wu; Y. Yu",The University of Hong Kong; The University of Hong Kong; Deepwise AI Lab; The University of Hong Kong,2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"2 Nov 2021","2021","","","4050","4059","Unsupervised domain adaptation (UDA) in semantic segmentation is a fundamental yet promising task relieving the need for laborious annotation works. However, the domain shifts/discrepancies problem in this task compromise the final segmentation performance. Based on our observation, the main causes of the domain shifts are differences in imaging conditions, called image-level domain shifts, and differences in object category configurations called category-level domain shifts. In this paper, we propose a novel UDA pipeline that unifies image-level alignment and category-level feature distribution regularization in a coarse-to-fine manner. Specifically, on the coarse side, we propose a photometric alignment module that aligns an image in the source domain with a reference image from the target domain using a set of image-level operators; on the fine side, we propose a category-oriented triplet loss that imposes a soft constraint to regularize category centers in the source domain and a self-supervised consistency regularization method in the target domain. Experimental results show that our proposed pipeline improves the generalization capability of the final segmentation model and significantly outperforms all previous state-of-the-arts.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00404","Research and Development; Impact Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577466","","Image segmentation;Adaptation models;Computer vision;Annotations;Computational modeling;Semantics;Pipelines","","41","","37","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Unbiased Subclass Regularization for Semi-Supervised Semantic Segmentation","D. Guan; J. Huang; A. Xiao; S. Lu","Singtel Cognitive and Artificial Intelligence Lab for Enterprises, Nanyang Technological University; Singtel Cognitive and Artificial Intelligence Lab for Enterprises, Nanyang Technological University; Singtel Cognitive and Artificial Intelligence Lab for Enterprises, Nanyang Technological University; Singtel Cognitive and Artificial Intelligence Lab for Enterprises, Nanyang Technological University",2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"27 Sep 2022","2022","","","9958","9968","Semi-supervised semantic segmentation learns from small amounts of labelled images and large amounts of unlabelled images, which has witnessed impressive progress with the recent advance of deep neural networks. However, it often suffers from severe class-bias problem while exploring the unlabelled images, largely due to the clear pixel-wise class imbalance in the labelled images. This paper presents an unbiased subclass regularization network (USRN) that alleviates the class imbalance issue by learning class-unbiased segmentation from balanced subclass distributions. We build the balanced subclass distributions by clustering pixels of each original class into multiple subclasses of similar sizes, which provide class-balanced pseudo supervision to regularize the class-biased segmentation. In addition, we design an entropy-based gate mechanism to coordinate learning between the original classes and the clustered subclasses which facilitates subclass regularization effectively by suppressing unconfident subclass predictions. Extensive experiments over multiple public benchmarks show that USRN achieves superior performance as compared with the state-of-the-art.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879440","Self-& semi-& meta- Segmentation;grouping and shape analysis","Deep learning;Image segmentation;Semantics;Neural networks;Object detection;Logic gates;Semisupervised learning","","33","","73","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Semi-supervised Deep Learning via Transformation Consistency Regularization for Remote Sensing Image Semantic Segmentation","B. Zhang; Y. Zhang; Y. Li; Y. Wan; H. Guo; Z. Zheng; K. Yang","Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Basic Geographic Information Center of Guizhou Province, Guizhou, China",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"10 Jul 2023","2023","16","","5782","5796","Deep convolutional neural networks have gotten a lot of press in the last several years, especially in domains like computer vision and remote sensing (RS). However, achieving superior performance with deep networks highly depends on a massive number of accurately labeled training samples. In real-world applications, gathering a large number of labeled samples is time consuming and labor intensive, especially for pixel-level data annotation. This dearth of labels in land-cover classification is especially pressing in the RS domain because high-precision high-quality labeled samples are extremely difficult to acquire, but unlabeled data are readily available. In this study, we offer a new semisupervised deep semantic labeling framework for the semantic segmentation of high-resolution RS images to take advantage of the limited amount of labeled examples and numerous unlabeled samples. Our model uses transformation consistency regularization to encourage consistent network predictions under different random transformations or perturbations. We try three different transforms to compute the consistency loss and analyze their performance. Then, we present a deep semisupervised semantic labeling technique by using a hybrid transformation consistency regularization. A weighted sum of losses, which contains a supervised term computed on labeled samples and an unsupervised regularization term computed on unlabeled data, may be used to update the network parameters in our technique. Our comprehensive experiments on two RS datasets confirmed that the suggested approach utilized latent information from unlabeled samples to obtain more precise predictions and outperformed existing semisupervised algorithms in terms of performance. Our experiments further demonstrated that our semisupervised semantic labeling strategy has the potential to partially tackle the problem of limited labeled samples for high-resolution RS image land-cover segmentation.","2151-1535","","10.1109/JSTARS.2022.3203750","National Natural Science Foundation of China(grant numbers:42030102,41971284); Hubei Natural Science Foundation(grant numbers:2020CFA003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875010","Consistency regularization;convolutional neural network (CNN);semantic segmentation;semisupervised learning (SSL);unlabeled data;remote sensing (RS) imagery","Semantics;Image segmentation;Labeling;Feature extraction;Perturbation methods;Earth;Deep learning","","21","","70","CCBYNCND","2 Sep 2022","","","IEEE","IEEE Journals"
"Domain Adaptive Semantic Segmentation via Regional Contrastive Consistency Regularization","Q. Zhou; C. Zhuang; R. Yi; X. Lu; L. Ma",Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Deakin University; Shanghai Jiao Tong University,2022 IEEE International Conference on Multimedia and Expo (ICME),"26 Aug 2022","2022","","","01","06","Unsupervised domain adaptation (UDA) for semantic seg-mentation has been well-studied in recent years. However, most existing works largely neglect the local regional consis-tency across different domains, and are less robust to changes in outdoor environments. In this paper, we propose a novel and fully end-to-end trainable approach, called regional contrastive consistency regularization (RCCR) for domain adaptive semantic segmentation. Our core idea is to pull the sim-ilar regional features extracted from the same location of dif-ferent images, i.e., the original image and augmented image, to be closer, and meanwhile push the features from the dif-ferent locations of the two images to be separated. We pro-pose a region-wise contrastive loss with two sampling strate-gies to realize effective regional consistency. Besides, we present momentum projection heads, where the teacher pro-jection head is the exponential moving average of the student. Finally, a memory bank mechanism is designed to learn more robust and stable region-wise features under varying environ-ments. Extensive experiments demonstrate that our approach outperforms the state-of-the-art methods.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9859793","National Key Research and Development Program of China(grant numbers:2019YFC1521104); National Natural Science Foundation of China(grant numbers:72192821,61972157); Shanghai Science and Technology Commission(grant numbers:21511101200,22YF1420300); National Social Science Fund(grant numbers:I8ZD22); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859793","Domain Adaptation;Semantic Segmen-tation;Contrastive Learning","Image segmentation;Head;Semantics;Feature extraction","","20","","25","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Latent Space Regularization for Unsupervised Domain Adaptation in Semantic Segmentation","F. Barbato; M. Toldo; U. Michieli; P. Zanuttigh","Department of Information Engineering, University of Padova; Department of Information Engineering, University of Padova; Department of Information Engineering, University of Padova; Department of Information Engineering, University of Padova",2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),"1 Sep 2021","2021","","","2829","2839","Deep convolutional neural networks for semantic segmentation achieve outstanding accuracy, however they also have a couple of major drawbacks: first, they do not generalize well to distributions slightly different from the one of the training data; second, they require a huge amount of labeled data for their optimization. In this paper, we introduce feature-level space-shaping regularization strategies to reduce the domain discrepancy in semantic segmentation. In particular, for this purpose we jointly enforce a clustering objective, a perpendicularity constraint and a norm alignment goal on the feature vectors corresponding to source and target samples. Additionally, we propose a novel measure able to capture the relative efficacy of an adaptation strategy compared to supervised training. We verify the effectiveness of such methods in the autonomous driving setting achieving state-of-the-art results in multiple synthetic-to-real road scenes benchmarks.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523097","","Training;Roads;Semantics;Employment;Training data;Benchmark testing;Particle measurements","","12","","55","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"Label Propagation and Contrastive Regularization for Semisupervised Semantic Segmentation of Remote Sensing Images","Z. Yang; Z. Yan; W. Diao; Q. Zhang; Y. Kang; J. Li; X. Li; X. Sun","Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, Beijing Institute of Tracking and Communication Technology, Beijing, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Geoscience and Remote Sensing,"31 May 2023","2023","61","","1","18","Remarkable progress based on deep neural networks has been achieved in the semantic segmentation of remote sensing images (RSIs). However, pixel-level labeling is expensive for RSIs. Semisupervised semantic segmentation becomes an alternative approach to reduce the cost of annotation, and it is crucial to utilize efficiently a large number of unlabeled data. Nevertheless, inevitably, there is an unbalanced class distribution between labeled and unlabeled data in a remote sensing scene. Existing semisupervised methods train unlabeled images in isolation from labeled images and only learn reliable pixel pseudo-labels, leading to underutilization of unlabeled images. This article proposes a novel semisupervised semantic segmentation approach based on label propagation and contrastive regularization for RSIs. Specifically, the unlabeled images are augmented by randomly copy-pasting the class regions from labeled images. A prototype feature constraint module is used to enforce the constraint on the pixel features of unlabeled images relying on the prototype features from labeled images, achieving feature alignment on the entire dataset. Furthermore, we present the region contrastive learning (RCL) module that guides the model to learn feature consistency under different perturbations and compact feature representations over class regions on unlabeled images. Extensive experimental results on multiple remote sensing datasets demonstrate that our proposed approach achieves superior performance compared with state-of-the-art semisupervised semantic segmentation methods.","1558-0644","","10.1109/TGRS.2023.3277203","National Natural Science Foundation of China(grant numbers:62171436); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10128868","Contrastive regularization;label propagation;remote sensing images (RSIs);semantic segmentation;semisupervised learning (SSL)","Semantic segmentation;Training;Perturbation methods;Remote sensing;Prototypes;Reliability;Sensors","","7","","61","IEEE","17 May 2023","","","IEEE","IEEE Journals"
"Self-Attentive Local Aggregation Learning With Prototype Guided Regularization for Point Cloud Semantic Segmentation of High-Speed Railways","Z. Wang; Y. Geng; L. Jia; Y. Qin; Y. Chai; L. Tong; K. Liu","State Key Laboratory of Rail Traffic Control and Safety and the Key Laboratory of Railway Industry of Proactive Safety and Risk Control, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Rail Traffic Control and Safety and the Key Laboratory of Railway Industry of Proactive Safety and Risk Control, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Rail Traffic Control and Safety and the Key Laboratory of Railway Industry of Proactive Safety and Risk Control, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Rail Traffic Control and Safety and the Key Laboratory of Railway Industry of Proactive Safety and Risk Control, Beijing Jiaotong University, Beijing, China; JIT Research Institute, Changchun Jilin University Zhengyuan Information Technologies Company Ltd., Beijing, China; State Key Laboratory of Rail Traffic Control and Safety and the Key Laboratory of Railway Industry of Proactive Safety and Risk Control, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Rail Traffic Control and Safety and the Key Laboratory of Railway Industry of Proactive Safety and Risk Control, Beijing Jiaotong University, Beijing, China",IEEE Transactions on Intelligent Transportation Systems,"4 Oct 2023","2023","24","10","11157","11170","Point cloud semantic segmentation for railway infrastructures is an essential step towards establishing railway digital twins. Deep learning-based methods have shown great potential in this field compared to traditional methods that rely on hand-crafted features. However, deep learning-based methods for railway point clouds still face typical challenges that need to be addressed. In this regard, we propose a novel learning framework named SALAProNet, which consists of a set of effective and concise modular solutions. The first challenge addressed is the massive data scale of railway point clouds, which makes it difficult to directly process large-scale point clouds due to memory limitations. To solve this problem, we adapt efficient random sampling in the network and propose the Self-Attentive Aggregation (SAA) module based on an attention mechanism to greatly expand the receptive field, which covers the unsampled points and successfully retains information in a high-dimensional feature space. The second challenge is fine-grained segmentation, where we propose the Local Geometry Embedding (LGE) module to embed local geometry. With the help of context information provided by SAA, the network can perform fine-grained segmentation for railway infrastructures. The third challenge is the insufficient generalization ability of the network, where we propose a Prototype Guided Regularization (PGR) method to guide the network to segment the point cloud among railways with different construction standards. This method enhances the network’s interpretability and improves its generalization ability. We have validated our proposed framework through experiments on different datasets, and it outperforms state-of-the-art approaches.","1558-0016","","10.1109/TITS.2023.3281352","National Key Research and Development Program of China(grant numbers:2022YFB4300601); National Natural Science Foundation of China(grant numbers:61833002); Research Project of State Key Laboratory of Rail Traffic Control and Safety(grant numbers:RCS2022ZT005); Research Project of China State Railway Group Company Ltd.(grant numbers:P2022X001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10144473","Attention mechanism;digital twin;high-speed railway;infrastructure;point cloud semantic segmentation;prototype guided regularization","Point cloud compression;Rail transportation;Semantic segmentation;Wires;Geometry;Three-dimensional displays;Semantics","","4","","46","IEEE","5 Jun 2023","","","IEEE","IEEE Journals"
"RankMatch: Exploring the Better Consistency Regularization for Semi-Supervised Semantic Segmentation","H. Mai; R. Sun; T. Zhang; F. Wu",University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China,2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),"16 Sep 2024","2024","","","3391","3401","The key lie in semi-supervised semantic segmentation is how to fully exploit substantial unlabeled data to im-prove the model's generalization performance by resorting to constructing effective supervision signals. Most methods tend to directly apply contrastive learning to seek additional supervision to complement independent regular pixel-wise consistency regularization. However, these methods tend not to be preferred ascribed to their complicated designs, heavy memory footprints and susceptibility to confirmation bias. In this paper, we analyze the bottlenecks exist in con-trastive learning-based methods and offer a fresh perspective on inter-pixel correlations to construct more safe and effective supervision signals, which is in line with the nature of semantic segmentation. To this end, we develop a coherent RankMatch network, including the construction of representative agents to model inter-pixel correlation beyond regular individual pixel-wise consistency, and fur-ther unlock the potential of agents by modeling inter-agent relationships in pursuit of rank-aware correlation consis-tency. Extensive experimental results on multiple bench-marks, including mitochondria segmentation, demonstrate that RankMatch performs favorably against state-of-the-art methods. Particularly in the low-data regimes, RankMatch achieves significant improvements.","2575-7075","979-8-3503-5300-6","10.1109/CVPR52733.2024.00326","National Defense Basic Scientific Research Program of China(grant numbers:JCKY2021601B013); Youth Innovation Promotion Association CAS(grant numbers:2018166); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10656404","","Learning systems;Computer vision;Correlation;Mitochondria;Semantic segmentation;Computational modeling;Contrastive learning","","3","","62","IEEE","16 Sep 2024","","","IEEE","IEEE Conferences"
"BRG: Bidirectional Regularization Guidance for Unsupervised Domain Adaptation Semantic Segmentation","C. Rao; W. Fan; X. Yang; X. Wei; D. Zhou","School of Software Engineering, National and Local Joint Engineering Laboratory of Computer Aided Design, Dalian University, Dalian, China; School of Software Engineering, National and Local Joint Engineering Laboratory of Computer Aided Design, Dalian University, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Software Engineering, National and Local Joint Engineering Laboratory of Computer Aided Design, Dalian University, Dalian, China",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","9","Unsupervised Domain Adaptation Semantic Segmentation (UDASS) aims to harness labeled data from the source domain alongside unlabeled data from the target domain to effectively segment target domain images. While self-training has achieved tremendous success in UDASS, most existing methods heavily rely on source data and lack of sufficient learning from target data, resulting in a performance decline. To address this issue, this paper introduces a Bidirectional Regularization Guidance (BRG) method, which combines a Target Perturbation Consistency (TPC) module and a thing-class ImageNet Feature Distance Reweighting (FDR) module to provide effective regularization guidance. Specifically, the TPC module is introduced to perturb the target stream by masking at the input level and adding feature noise at the feature level. This module employs a target perturbation consistency loss to penalize inconsistencies between perturbed student predictions and teacher model predictions, thereby facilitating improved learning of contextual information by the student model from the target images. To further enhance the model’s generalization ability to the target domain, We propose an FDR module that employs a transferability map to calculate a reweighted graph, helping to effectively align source features with ImageNet features by reweighting the feature distances, especially those with lower transferability Through rigorous experimentation in standard UDASS settings—training with synthetic labeled and real unlabeled data—BRG outperforms baseline model on GTAV→Cityscapes and SYNTHIA→Cityscapes.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10651508","National Key Research and Development Program of China; National Natural Science Foundation of China; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10651508","Self-training;Semantic Segmentation;Unsupervised Domain Adaptation","Adaptation models;Perturbation methods;Semantic segmentation;Noise;Neural networks;Object detection;Predictive models","","","","44","IEEE","9 Sep 2024","","","IEEE","IEEE Conferences"
"Enhancing Lightweight Remote Sensing Semantic Segmentation via Weak Consistency Regularization","Z. Chen; S. Xiao; W. Man; D. -H. Wang; Y. He; S. Zhu","School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; Xiamen Key Laboratory of Visual Perception Technology and Applications, Reconova Technologies Co., Ltd, Xiamen, China; School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","8","Remote sensing image semantic segmentation has widespread applications in urban planning and land monitoring. In recent years, U-Net and its variant networks have almost dominated the research in the field of semantic segmentation. However, many models pay less attention to computational efficiency, rendering them ineffective in scenarios with computational resource and timeliness constraints, such as autonomous driving and disaster monitoring. To address this issue, we propose the USA-Net (UNet-like with Shifted Axial), a lightweight hybrid model based on convolution and MLP (Multi-Layer Perceptron). Specifically, we design the ST Block (Shift Tokenized Block), which introduces local features into global operations in MLP through spatial shift, and then use ELCM (Efficient Large-kernel Convolution Module) to enlarge the model’s receptive field and learn the shape features of objects. Additionally, we propose a new semi-supervised learning framework to further improve the model’s generalization performance. On the ISPRS Vaihingen and ISPRS Potsdam datasets, USA-Net significantly outperforms most state-of-the-art methods in terms of segmentation accuracy and efficiency.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10651009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10651009","semantic segmentation;remote sensing image;lightweight hybrid model;semi-supervised learning","Accuracy;Convolution;Shape;Semantic segmentation;Computational modeling;Urban planning;Semisupervised learning","","","","38","IEEE","9 Sep 2024","","","IEEE","IEEE Conferences"
"Consistency Regularization Based on Masked Image Modeling for Semisupervised Remote Sensing Semantic Segmentation","M. Cai; H. Chen; T. Zhang; Y. Zhuang; L. Chen","National Key Laboratory of Science and Technology on Space-Born Intelligent Information Processing, Beijing Institute of Technology, Beijing, China; National Key Laboratory of Science and Technology on Space-Born Intelligent Information Processing, Beijing Institute of Technology, Beijing, China; National Key Laboratory of Science and Technology on Space-Born Intelligent Information Processing, Beijing Institute of Technology, Beijing, China; National Key Laboratory of Science and Technology on Space-Born Intelligent Information Processing, Beijing Institute of Technology, Beijing, China; National Key Laboratory of Science and Technology on Space-Born Intelligent Information Processing, Beijing Institute of Technology, Beijing, China",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"2 Oct 2024","2024","17","","17442","17460","Semisupervised semantic segmentation aims to effectively leverage both unlabeled and scare labeled images, reducing the reliance on labor-intensive pixel-level labeling for extensive training processes. The leading semisupervised learning method, consistency regularization, employs weak and strong data augmentations to diversify input representations. Ultimately the model is compelled to maintain consistent predictions across different input views, thus boosting the model's generalization. However, previous methods suffered from limited input representation space introduced by linear transformations such as cutmix. To address such issue, a consistency regularization based on masked image modeling (MIM) called MIMSeg is proposed to achieve accurate segmentation with limited labeled images. First, MIM pixel-wise perception with ViT encoder-decoder lays the foundation for expanding the data representation space. Second, collaborating with weak data augmentations, two MIM-related strong data augmentations are developed to generate more challenging input views for consistent predictions. Precisely, weak data augmentations are employed to replicate input views from various perspectives while a controllable generative strong data augmentation called masked image reconstruction (MIR) is crafted to simulate multiple imaging diversity while preserving the original semantic information intact. In addition, a more severe strong data augmentation masked context perturbation (MCP) is designed to further generate more challenging input views and alleviate semantic deficiency via masked category prediction. Leveraging the MIM perception and two MIM-related strong data augmentations, the model is compelled to achieve consistency predictions across diverse input views from weak data augmentations, MIR and MCP. These components result in the generation of more stable pixel-level pseudo-labels and facilitate collaborative training between unlabeled and labeled images. Extensive experiments have shown that MIMSeg can achieve state-of-the-art performance in pixel-level prediction with very limited sample annotations.","2151-1535","","10.1109/JSTARS.2024.3435509","General Program of the National Natural Science Foundation of China(grant numbers:62371048); National Science Foundation for Young Scientists of China(grant numbers:62101046,JCKY2021602B037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10623542","Consistency regularization;masked image modeling (MIM);semisupervised semantic segmentation","Semantics;Data augmentation;Semantic segmentation;Data models;Training;Predictive models;Imaging","","","","86","CCBYNCND","5 Aug 2024","","","IEEE","IEEE Journals"
"Learnable contextual regularization for semantic segmentation of indoor scene images","J. Chu; X. Xiao; G. Meng; L. Wang; C. Pan","Institute of Computer Vision, Nanchang Hangkong University; National Laboratory of Pattern Recognition, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Chinese Academy of Sciences; National Laboratory of Pattern Recognition, Chinese Academy of Sciences",2017 IEEE International Conference on Image Processing (ICIP),"22 Feb 2018","2017","","","1267","1271","Semantic segmentation of indoor scene images has a wide range of applications. However, due to a large number of classes and uneven distribution in indoor scenes, mislabels are often made when facing small objects or boundary regions. Technically, contextual information may benefit for segmentation results, but has not yet been exploited sufficiently. In this paper, we propose a learnable contextual regularization model for enhancing the semantic segmentation results of color indoor scene images. This regularization model is combined with a deep convolutional segmentation network without significantly increasing the number of additional parameters. Our model, derived from the inherent contextual regularization on the indoor scene objects, benefits much from the learnable constraint layers bridging the lower layers and the higher layers in the deep convolutional network. The constraint layers are further integrated with a weighted L1-norm based contextual regularization between the neighboring pixels of RGB values to improve the segmentation results. Experimental results on NYUDv2 indoor scene dataset demonstrate the effectiveness and efficiency of the proposed method.","2381-8549","978-1-5090-2175-8","10.1109/ICIP.2017.8296485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8296485","Deep convolutional neural networks;Semantic segmentation;Contextual constraints;End-to-end training","Image segmentation;Semantics;Kernel;Training;Task analysis;Computer architecture;Convolution","","","","28","IEEE","22 Feb 2018","","","IEEE","IEEE Conferences"
"Consistency Regularization for Semi-Supervised Semantic Segmentation of Flood Regions From SAR Images","G. Savitha; S. Girisha; P. Sughosh; D. K. Shetty; J. Mymbilly Balakrishnan; R. Paul; N. Naik","Department of Data Science and Computer Applications, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Department of Data Science and Computer Applications, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Department of Civil Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Department of Data Science and Computer Applications, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India; Department of Emergency Medicine, Kasturba Medical College, Manipal Academy of Higher Education, Manipal, India; Department of Radiation Oncology, Massachusetts General Hospital, Boston, MA, USA; Department of Mechanical and Industrial Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India",IEEE Access,"17 Jan 2025","2025","13","","9642","9653","As one of the most powerful natural catastrophes, floods pose serious risks to people’s lives, the integrity of infrastructure, and agricultural landscapes, which increases the toll they take on the economy and society. As a result, it becomes essential to continuously monitor these areas of vulnerability in order to support effective disaster response and mitigation efforts. Accurately defining the extent of floods is a problem for traditional flood mapping approaches, which emphasizes the vital need for modern technologies such as Synthetic Aperture Radar (SAR) imaging. Additionally, there is a need to develop computer-aided tools specifically designed for automatically identifying areas that are vulnerable to flooding using SAR data. Nonetheless, the lack of consistent large datasets presents a barrier that prevents these algorithms from progressing and being used in real-world scenarios. For this reason, the present study aims to develop a semi-supervised semantic segmentation algorithm for accurate flood region delineation in SAR data. In particular, the paper proposes labeling unannotated instances of data using a pseudo-label generation strategy. In order to accomplish this, the study suggests using a self-supervised trained teacher model to generate pseudo-labels and speed up the training procedure. The teacher model is then trained with a student model to efficiently extract features from the labeled data. Furthermore, the study presents a new semantic segmentation technique that uses convolutional neural networks to automatically identify flooded areas in SAR images. A comprehensive assessment conducted on publicly available datasets produces promising results. These results confirm the usefulness and possible relevance of the suggested methodology in enhancing efforts related to flood zone identification and management.","2169-3536","","10.1109/ACCESS.2025.3526244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829568","Semi-supervised learning;flood mapping;SAR images;semantic segmentation","Floods;Radar polarimetry;Semantic segmentation;Feature extraction;Synthetic aperture radar;Semantics;Noise;Data models;Semisupervised learning;Accuracy","","","","51","CCBY","6 Jan 2025","","","IEEE","IEEE Journals"
